{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8faae2d7",
   "metadata": {},
   "source": [
    "# 1. 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e300435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd07f30b",
   "metadata": {},
   "source": [
    "# 2. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad485fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "data = load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab47f7d8",
   "metadata": {},
   "source": [
    "# 3. X, y 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e15cc855",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a815cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size= 0.15, random_state = 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a5984",
   "metadata": {},
   "source": [
    "# 4. 머신러닝 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "326c6fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "dt_model= DecisionTreeRegressor()\n",
    "dt_model.fit(x_train, y_train)\n",
    "\n",
    "dt_pred = dt_model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43f26be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.35063888484494\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "print(MSE(y_val, dt_pred)**(0.5))\n",
    "\n",
    "sns.scatterplot(x = y_val, y = dt_pred)\n",
    "plt.ylabel('dt_pred')\n",
    "plt.xlabel('y_val')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efd6382",
   "metadata": {},
   "source": [
    "# 5. 딥러닝 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6f58609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                704       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,817\n",
      "Trainable params: 2,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1. 세션클리어\n",
    "clear_session()\n",
    "\n",
    "# 2. 모델 선언\n",
    "model = Sequential()\n",
    "\n",
    "# 3. 모델 블록 조립\n",
    "model.add(Dense(units = 64, activation = 'relu', input_shape = (10,)))\n",
    "model.add(Dense(units = 32, activation = 'relu'))\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "# 4. 모델 컴파일\n",
    "model.compile(loss = 'mse',\n",
    "              metrics=['mae'],\n",
    "              optimizer = 'adam')\n",
    "\n",
    "# 5. 요약\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5c2a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "es = EarlyStopping(monitor='val_loss',\n",
    "                   min_delta=0,\n",
    "                   patience=5,\n",
    "                   verbose=1)\n",
    "\n",
    "mc = ModelCheckpoint(filepath = './best_model.h5', \n",
    "                     monitor='val_loss', \n",
    "                     save_best_only= True, \n",
    "                     save_weights_only= False, \n",
    "                     verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ca54de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/3 [=========>....................] - ETA: 1s - loss: 29726.6914 - mae: 153.1317\n",
      "Epoch 1: val_loss improved from inf to 30001.53320, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 1s 129ms/step - loss: 28984.9805 - mae: 151.6853 - val_loss: 30001.5332 - val_mae: 159.8628\n",
      "Epoch 2/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 29308.9844 - mae: 150.0340\n",
      "Epoch 2: val_loss improved from 30001.53320 to 29988.42383, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28973.3340 - mae: 151.6478 - val_loss: 29988.4238 - val_mae: 159.8221\n",
      "Epoch 3/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 27158.5312 - mae: 145.7713\n",
      "Epoch 3: val_loss improved from 29988.42383 to 29974.07031, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 28960.3340 - mae: 151.6061 - val_loss: 29974.0703 - val_mae: 159.7776\n",
      "Epoch 4/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 29982.1426 - mae: 154.7580\n",
      "Epoch 4: val_loss improved from 29974.07031 to 29958.16406, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 28946.3535 - mae: 151.5605 - val_loss: 29958.1641 - val_mae: 159.7284\n",
      "Epoch 5/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 28355.0547 - mae: 151.4939\n",
      "Epoch 5: val_loss improved from 29958.16406 to 29940.47656, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 28930.7070 - mae: 151.5097 - val_loss: 29940.4766 - val_mae: 159.6741\n",
      "Epoch 6/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 29218.1836 - mae: 150.4586\n",
      "Epoch 6: val_loss improved from 29940.47656 to 29920.73047, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 28912.9824 - mae: 151.4535 - val_loss: 29920.7305 - val_mae: 159.6135\n",
      "Epoch 7/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 27504.3320 - mae: 147.0128\n",
      "Epoch 7: val_loss improved from 29920.73047 to 29898.65430, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 28893.5527 - mae: 151.3909 - val_loss: 29898.6543 - val_mae: 159.5459\n",
      "Epoch 8/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 28956.9863 - mae: 153.1190\n",
      "Epoch 8: val_loss improved from 29898.65430 to 29873.92578, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28871.5000 - mae: 151.3204 - val_loss: 29873.9258 - val_mae: 159.4702\n",
      "Epoch 9/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 27471.4199 - mae: 146.6286\n",
      "Epoch 9: val_loss improved from 29873.92578 to 29846.19922, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28846.6230 - mae: 151.2414 - val_loss: 29846.1992 - val_mae: 159.3852\n",
      "Epoch 10/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 33040.8320 - mae: 162.8955\n",
      "Epoch 10: val_loss improved from 29846.19922 to 29815.09375, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 28819.5195 - mae: 151.1534 - val_loss: 29815.0938 - val_mae: 159.2900\n",
      "Epoch 11/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 28864.7031 - mae: 153.0096\n",
      "Epoch 11: val_loss improved from 29815.09375 to 29780.31055, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28788.2891 - mae: 151.0544 - val_loss: 29780.3105 - val_mae: 159.1837\n",
      "Epoch 12/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 30050.9707 - mae: 154.4985\n",
      "Epoch 12: val_loss improved from 29780.31055 to 29741.40039, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 28753.5762 - mae: 150.9440 - val_loss: 29741.4004 - val_mae: 159.0648\n",
      "Epoch 13/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 27545.3164 - mae: 146.4408\n",
      "Epoch 13: val_loss improved from 29741.40039 to 29697.92969, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 28714.4902 - mae: 150.8208 - val_loss: 29697.9297 - val_mae: 158.9321\n",
      "Epoch 14/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 29475.8555 - mae: 153.9564\n",
      "Epoch 14: val_loss improved from 29697.92969 to 29649.36719, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 28672.0527 - mae: 150.6830 - val_loss: 29649.3672 - val_mae: 158.7838\n",
      "Epoch 15/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 30340.3984 - mae: 153.4830\n",
      "Epoch 15: val_loss improved from 29649.36719 to 29595.82031, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 28623.9824 - mae: 150.5298 - val_loss: 29595.8203 - val_mae: 158.6201\n",
      "Epoch 16/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 29348.0703 - mae: 151.5872\n",
      "Epoch 16: val_loss improved from 29595.82031 to 29536.70703, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28570.4395 - mae: 150.3600 - val_loss: 29536.7070 - val_mae: 158.4393\n",
      "Epoch 17/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 29827.8340 - mae: 154.4637\n",
      "Epoch 17: val_loss improved from 29536.70703 to 29471.26367, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 28512.3203 - mae: 150.1736 - val_loss: 29471.2637 - val_mae: 158.2392\n",
      "Epoch 18/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 27445.2383 - mae: 146.1552\n",
      "Epoch 18: val_loss improved from 29471.26367 to 29399.27344, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28446.7539 - mae: 149.9670 - val_loss: 29399.2734 - val_mae: 158.0191\n",
      "Epoch 19/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 26415.0527 - mae: 144.5733\n",
      "Epoch 19: val_loss improved from 29399.27344 to 29320.04688, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28375.3574 - mae: 149.7403 - val_loss: 29320.0469 - val_mae: 157.7769\n",
      "Epoch 20/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 28318.2695 - mae: 149.3255\n",
      "Epoch 20: val_loss improved from 29320.04688 to 29233.39062, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 28298.7695 - mae: 149.4928 - val_loss: 29233.3906 - val_mae: 157.5116\n",
      "Epoch 21/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 27650.1016 - mae: 145.3815\n",
      "Epoch 21: val_loss improved from 29233.39062 to 29139.85352, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 28213.0430 - mae: 149.2199 - val_loss: 29139.8535 - val_mae: 157.2246\n",
      "Epoch 22/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 25937.2852 - mae: 143.4268\n",
      "Epoch 22: val_loss improved from 29139.85352 to 29038.40625, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 28120.9395 - mae: 148.9258 - val_loss: 29038.4062 - val_mae: 156.9130\n",
      "Epoch 23/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 28707.1973 - mae: 150.3092\n",
      "Epoch 23: val_loss improved from 29038.40625 to 28928.75977, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 28021.7070 - mae: 148.6066 - val_loss: 28928.7598 - val_mae: 156.5758\n",
      "Epoch 24/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 24900.3906 - mae: 141.1047\n",
      "Epoch 24: val_loss improved from 28928.75977 to 28810.36328, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 27913.2891 - mae: 148.2630 - val_loss: 28810.3633 - val_mae: 156.2111\n",
      "Epoch 25/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 28650.9961 - mae: 150.1303\n",
      "Epoch 25: val_loss improved from 28810.36328 to 28682.62695, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 27799.1641 - mae: 147.8902 - val_loss: 28682.6270 - val_mae: 155.8170\n",
      "Epoch 26/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 28043.8945 - mae: 148.4280\n",
      "Epoch 26: val_loss improved from 28682.62695 to 28546.14258, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 27672.7773 - mae: 147.4862 - val_loss: 28546.1426 - val_mae: 155.3949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 29807.0273 - mae: 152.8310\n",
      "Epoch 27: val_loss improved from 28546.14258 to 28399.38281, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 27541.0273 - mae: 147.0569 - val_loss: 28399.3828 - val_mae: 154.9407\n",
      "Epoch 28/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 30994.9238 - mae: 154.8561\n",
      "Epoch 28: val_loss improved from 28399.38281 to 28243.00000, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 27398.9863 - mae: 146.5951 - val_loss: 28243.0000 - val_mae: 154.4555\n",
      "Epoch 29/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 25913.2188 - mae: 142.5570\n",
      "Epoch 29: val_loss improved from 28243.00000 to 28077.10352, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 27244.4492 - mae: 146.1017 - val_loss: 28077.1035 - val_mae: 153.9391\n",
      "Epoch 30/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 25130.4258 - mae: 141.4048\n",
      "Epoch 30: val_loss improved from 28077.10352 to 27900.83398, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 27082.8535 - mae: 145.5762 - val_loss: 27900.8340 - val_mae: 153.3886\n",
      "Epoch 31/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 26371.1641 - mae: 145.5322\n",
      "Epoch 31: val_loss improved from 27900.83398 to 27713.47656, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 26912.5508 - mae: 145.0194 - val_loss: 27713.4766 - val_mae: 152.8021\n",
      "Epoch 32/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 25907.5059 - mae: 143.2403\n",
      "Epoch 32: val_loss improved from 27713.47656 to 27514.95898, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 26728.0234 - mae: 144.4200 - val_loss: 27514.9590 - val_mae: 152.1784\n",
      "Epoch 33/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 26226.3184 - mae: 142.2442\n",
      "Epoch 33: val_loss improved from 27514.95898 to 27303.92578, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 26536.3965 - mae: 143.7866 - val_loss: 27303.9258 - val_mae: 151.5136\n",
      "Epoch 34/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 27654.4844 - mae: 145.7127\n",
      "Epoch 34: val_loss improved from 27303.92578 to 27081.75195, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 26335.0762 - mae: 143.1187 - val_loss: 27081.7520 - val_mae: 150.8111\n",
      "Epoch 35/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 26409.2305 - mae: 144.3461\n",
      "Epoch 35: val_loss improved from 27081.75195 to 26849.58594, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 26118.7637 - mae: 142.4050 - val_loss: 26849.5859 - val_mae: 150.0729\n",
      "Epoch 36/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 25580.6914 - mae: 141.1575\n",
      "Epoch 36: val_loss improved from 26849.58594 to 26606.02930, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 25892.8047 - mae: 141.6576 - val_loss: 26606.0293 - val_mae: 149.2944\n",
      "Epoch 37/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 25070.9863 - mae: 138.5297\n",
      "Epoch 37: val_loss improved from 26606.02930 to 26349.82227, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 25656.1172 - mae: 140.8685 - val_loss: 26349.8223 - val_mae: 148.4718\n",
      "Epoch 38/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 23662.5918 - mae: 133.3423\n",
      "Epoch 38: val_loss improved from 26349.82227 to 26080.66406, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 25407.8125 - mae: 140.0363 - val_loss: 26080.6641 - val_mae: 147.6032\n",
      "Epoch 39/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 27543.2266 - mae: 144.6722\n",
      "Epoch 39: val_loss improved from 26080.66406 to 25798.63477, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 25152.5527 - mae: 139.1612 - val_loss: 25798.6348 - val_mae: 146.6882\n",
      "Epoch 40/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 24972.8242 - mae: 137.2212\n",
      "Epoch 40: val_loss improved from 25798.63477 to 25505.40430, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 24875.7402 - mae: 138.2335 - val_loss: 25505.4043 - val_mae: 145.7305\n",
      "Epoch 41/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 25630.3945 - mae: 139.1181\n",
      "Epoch 41: val_loss improved from 25505.40430 to 25198.38086, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 24595.4395 - mae: 137.2649 - val_loss: 25198.3809 - val_mae: 144.7214\n",
      "Epoch 42/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 27141.6641 - mae: 145.8942\n",
      "Epoch 42: val_loss improved from 25198.38086 to 24878.19922, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 24301.6562 - mae: 136.2494 - val_loss: 24878.1992 - val_mae: 143.6626\n",
      "Epoch 43/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 25578.1445 - mae: 140.1302\n",
      "Epoch 43: val_loss improved from 24878.19922 to 24545.78320, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 23993.5059 - mae: 135.1790 - val_loss: 24545.7832 - val_mae: 142.5551\n",
      "Epoch 44/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 21946.6289 - mae: 128.7190\n",
      "Epoch 44: val_loss improved from 24545.78320 to 24203.21484, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 23670.0039 - mae: 134.0619 - val_loss: 24203.2148 - val_mae: 141.4041\n",
      "Epoch 45/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 21019.8398 - mae: 126.7273\n",
      "Epoch 45: val_loss improved from 24203.21484 to 23848.43164, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 23338.2461 - mae: 132.8994 - val_loss: 23848.4316 - val_mae: 140.2026\n",
      "Epoch 46/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 21563.4062 - mae: 126.0057\n",
      "Epoch 46: val_loss improved from 23848.43164 to 23478.85352, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 22998.2520 - mae: 131.6852 - val_loss: 23478.8535 - val_mae: 138.9421\n",
      "Epoch 47/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 24206.9922 - mae: 137.3995\n",
      "Epoch 47: val_loss improved from 23478.85352 to 23096.54883, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 22651.5703 - mae: 130.4187 - val_loss: 23096.5488 - val_mae: 137.6272\n",
      "Epoch 48/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 24111.9082 - mae: 134.8336\n",
      "Epoch 48: val_loss improved from 23096.54883 to 22705.73828, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 22284.5645 - mae: 129.0971 - val_loss: 22705.7383 - val_mae: 136.2687\n",
      "Epoch 49/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 24491.8379 - mae: 137.6733\n",
      "Epoch 49: val_loss improved from 22705.73828 to 22304.19531, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 21914.4805 - mae: 127.7280 - val_loss: 22304.1953 - val_mae: 134.8591\n",
      "Epoch 50/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 23626.3086 - mae: 133.2688\n",
      "Epoch 50: val_loss improved from 22304.19531 to 21893.91992, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 21529.3242 - mae: 126.3144 - val_loss: 21893.9199 - val_mae: 133.4047\n",
      "Epoch 51/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 21105.6797 - mae: 122.2153\n",
      "Epoch 51: val_loss improved from 21893.91992 to 21474.34570, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 21131.5938 - mae: 124.8471 - val_loss: 21474.3457 - val_mae: 131.9003\n",
      "Epoch 52/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 21622.2344 - mae: 127.4099\n",
      "Epoch 52: val_loss improved from 21474.34570 to 21043.52148, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 20736.1348 - mae: 123.3354 - val_loss: 21043.5215 - val_mae: 130.3380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 22790.4082 - mae: 129.6762\n",
      "Epoch 53: val_loss improved from 21043.52148 to 20603.03125, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 20321.5820 - mae: 121.7672 - val_loss: 20603.0312 - val_mae: 128.7215\n",
      "Epoch 54/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 23274.2480 - mae: 133.6726\n",
      "Epoch 54: val_loss improved from 20603.03125 to 20149.58594, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 19912.2148 - mae: 120.1428 - val_loss: 20149.5859 - val_mae: 127.0365\n",
      "Epoch 55/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 17782.5293 - mae: 113.3533\n",
      "Epoch 55: val_loss improved from 20149.58594 to 19692.93164, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 19464.1797 - mae: 118.4478 - val_loss: 19692.9316 - val_mae: 125.3150\n",
      "Epoch 56/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14520.1094 - mae: 101.6793\n",
      "Epoch 56: val_loss improved from 19692.93164 to 19224.41406, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 19023.3535 - mae: 116.7047 - val_loss: 19224.4141 - val_mae: 123.5248\n",
      "Epoch 57/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18019.4727 - mae: 111.5296\n",
      "Epoch 57: val_loss improved from 19224.41406 to 18745.31250, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 18585.4707 - mae: 114.9032 - val_loss: 18745.3125 - val_mae: 121.6696\n",
      "Epoch 58/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18267.2383 - mae: 112.2774\n",
      "Epoch 58: val_loss improved from 18745.31250 to 18260.14258, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 18133.4551 - mae: 113.0418 - val_loss: 18260.1426 - val_mae: 119.7635\n",
      "Epoch 59/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18158.3105 - mae: 112.3343\n",
      "Epoch 59: val_loss improved from 18260.14258 to 17771.66992, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 17674.6621 - mae: 111.1211 - val_loss: 17771.6699 - val_mae: 117.8117\n",
      "Epoch 60/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 20340.4570 - mae: 120.1771\n",
      "Epoch 60: val_loss improved from 17771.66992 to 17279.61914, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 17216.1426 - mae: 109.1554 - val_loss: 17279.6191 - val_mae: 115.8138\n",
      "Epoch 61/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18707.0742 - mae: 116.4128\n",
      "Epoch 61: val_loss improved from 17279.61914 to 16783.42578, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 16753.3145 - mae: 107.1678 - val_loss: 16783.4258 - val_mae: 113.7676\n",
      "Epoch 62/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 16861.6562 - mae: 106.6441\n",
      "Epoch 62: val_loss improved from 16783.42578 to 16287.48633, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 16279.6221 - mae: 105.1280 - val_loss: 16287.4863 - val_mae: 111.6845\n",
      "Epoch 63/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13419.0098 - mae: 91.9973\n",
      "Epoch 63: val_loss improved from 16287.48633 to 15790.51172, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 15800.3438 - mae: 103.0801 - val_loss: 15790.5117 - val_mae: 109.5569\n",
      "Epoch 64/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 15594.7881 - mae: 104.0099\n",
      "Epoch 64: val_loss improved from 15790.51172 to 15285.95215, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 15342.0830 - mae: 101.0099 - val_loss: 15285.9521 - val_mae: 107.3560\n",
      "Epoch 65/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 15316.7754 - mae: 101.1818\n",
      "Epoch 65: val_loss improved from 15285.95215 to 14780.13477, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 14867.6465 - mae: 98.8960 - val_loss: 14780.1348 - val_mae: 105.1056\n",
      "Epoch 66/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14319.8291 - mae: 93.6721\n",
      "Epoch 66: val_loss improved from 14780.13477 to 14274.90039, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 14389.1367 - mae: 96.7944 - val_loss: 14274.9004 - val_mae: 102.8123\n",
      "Epoch 67/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 16628.2188 - mae: 104.6405\n",
      "Epoch 67: val_loss improved from 14274.90039 to 13768.62207, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 13929.7178 - mae: 94.7121 - val_loss: 13768.6221 - val_mae: 100.4626\n",
      "Epoch 68/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14776.4004 - mae: 98.5175\n",
      "Epoch 68: val_loss improved from 13768.62207 to 13268.72168, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 13453.4766 - mae: 92.5781 - val_loss: 13268.7217 - val_mae: 98.1143\n",
      "Epoch 69/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 11228.7490 - mae: 82.7541\n",
      "Epoch 69: val_loss improved from 13268.72168 to 12776.18555, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 12978.1729 - mae: 90.5062 - val_loss: 12776.1855 - val_mae: 95.7887\n",
      "Epoch 70/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 11854.9902 - mae: 84.4601\n",
      "Epoch 70: val_loss improved from 12776.18555 to 12288.67285, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 12523.0518 - mae: 88.5137 - val_loss: 12288.6729 - val_mae: 93.4753\n",
      "Epoch 71/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13022.5498 - mae: 89.0242\n",
      "Epoch 71: val_loss improved from 12288.67285 to 11805.56543, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 12071.4805 - mae: 86.4285 - val_loss: 11805.5654 - val_mae: 91.1602\n",
      "Epoch 72/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 11147.8301 - mae: 83.4505\n",
      "Epoch 72: val_loss improved from 11805.56543 to 11326.89062, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 11628.1299 - mae: 84.4537 - val_loss: 11326.8906 - val_mae: 88.9116\n",
      "Epoch 73/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13417.2383 - mae: 92.0820\n",
      "Epoch 73: val_loss improved from 11326.89062 to 10859.60547, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 11194.4307 - mae: 82.4603 - val_loss: 10859.6055 - val_mae: 86.6928\n",
      "Epoch 74/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 10221.9863 - mae: 77.3897\n",
      "Epoch 74: val_loss improved from 10859.60547 to 10406.96875, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 10755.6572 - mae: 80.4982 - val_loss: 10406.9688 - val_mae: 84.4810\n",
      "Epoch 75/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 11000.0781 - mae: 82.7379\n",
      "Epoch 75: val_loss improved from 10406.96875 to 9965.68750, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 10345.6133 - mae: 78.5747 - val_loss: 9965.6875 - val_mae: 82.2719\n",
      "Epoch 76/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 10670.3926 - mae: 81.5316\n",
      "Epoch 76: val_loss improved from 9965.68750 to 9536.79297, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 9940.9746 - mae: 76.6222 - val_loss: 9536.7930 - val_mae: 80.1068\n",
      "Epoch 77/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9784.1768 - mae: 75.9590\n",
      "Epoch 77: val_loss improved from 9536.79297 to 9119.68750, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 9547.2480 - mae: 74.8528 - val_loss: 9119.6875 - val_mae: 77.9797\n",
      "Epoch 78/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9459.1348 - mae: 75.3126\n",
      "Epoch 78: val_loss improved from 9119.68750 to 8715.12793, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 9171.1680 - mae: 73.1013 - val_loss: 8715.1279 - val_mae: 75.9082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 8358.0186 - mae: 69.7668\n",
      "Epoch 79: val_loss improved from 8715.12793 to 8325.23047, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 8796.2666 - mae: 71.4330 - val_loss: 8325.2305 - val_mae: 73.8568\n",
      "Epoch 80/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7441.8364 - mae: 65.7086\n",
      "Epoch 80: val_loss improved from 8325.23047 to 7944.28564, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 8440.1162 - mae: 69.8426 - val_loss: 7944.2856 - val_mae: 71.8226\n",
      "Epoch 81/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7985.3579 - mae: 66.9888\n",
      "Epoch 81: val_loss improved from 7944.28564 to 7573.33154, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 8098.9673 - mae: 68.2859 - val_loss: 7573.3315 - val_mae: 69.8758\n",
      "Epoch 82/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7618.5776 - mae: 65.5445\n",
      "Epoch 82: val_loss improved from 7573.33154 to 7214.81836, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 7770.5127 - mae: 66.7981 - val_loss: 7214.8184 - val_mae: 67.9589\n",
      "Epoch 83/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7580.8818 - mae: 64.1891\n",
      "Epoch 83: val_loss improved from 7214.81836 to 6874.56934, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 7448.6157 - mae: 65.3248 - val_loss: 6874.5693 - val_mae: 66.1320\n",
      "Epoch 84/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 9358.8975 - mae: 75.1538\n",
      "Epoch 84: val_loss improved from 6874.56934 to 6548.24561, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 7157.7856 - mae: 64.0063 - val_loss: 6548.2456 - val_mae: 64.4554\n",
      "Epoch 85/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6497.0811 - mae: 60.4955\n",
      "Epoch 85: val_loss improved from 6548.24561 to 6240.18506, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 6857.9814 - mae: 62.6681 - val_loss: 6240.1851 - val_mae: 62.9733\n",
      "Epoch 86/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 7185.6050 - mae: 64.4661\n",
      "Epoch 86: val_loss improved from 6240.18506 to 5947.36719, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 6595.5518 - mae: 61.5858 - val_loss: 5947.3672 - val_mae: 61.6274\n",
      "Epoch 87/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6612.3174 - mae: 61.9351\n",
      "Epoch 87: val_loss improved from 5947.36719 to 5673.70068, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 6337.0190 - mae: 60.4504 - val_loss: 5673.7007 - val_mae: 60.3635\n",
      "Epoch 88/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5857.6196 - mae: 56.8748\n",
      "Epoch 88: val_loss improved from 5673.70068 to 5416.50977, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 6095.6445 - mae: 59.5504 - val_loss: 5416.5098 - val_mae: 59.1251\n",
      "Epoch 89/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4839.1274 - mae: 52.2942\n",
      "Epoch 89: val_loss improved from 5416.50977 to 5174.54395, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 5874.6860 - mae: 58.7078 - val_loss: 5174.5439 - val_mae: 57.9224\n",
      "Epoch 90/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 6339.4175 - mae: 61.5492\n",
      "Epoch 90: val_loss improved from 5174.54395 to 4949.10791, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 5673.5620 - mae: 57.9541 - val_loss: 4949.1079 - val_mae: 56.8325\n",
      "Epoch 91/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5759.9541 - mae: 59.4704\n",
      "Epoch 91: val_loss improved from 4949.10791 to 4739.35938, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 5478.3188 - mae: 57.2518 - val_loss: 4739.3594 - val_mae: 55.8172\n",
      "Epoch 92/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5488.0146 - mae: 57.1309\n",
      "Epoch 92: val_loss improved from 4739.35938 to 4542.91064, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 5304.1650 - mae: 56.5868 - val_loss: 4542.9106 - val_mae: 54.8153\n",
      "Epoch 93/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5061.5913 - mae: 54.4683\n",
      "Epoch 93: val_loss improved from 4542.91064 to 4362.78564, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 5143.4888 - mae: 56.0172 - val_loss: 4362.7856 - val_mae: 53.8884\n",
      "Epoch 94/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 5467.6143 - mae: 57.4163\n",
      "Epoch 94: val_loss improved from 4362.78564 to 4200.33301, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4993.5625 - mae: 55.5182 - val_loss: 4200.3330 - val_mae: 53.0094\n",
      "Epoch 95/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4835.3120 - mae: 55.3556\n",
      "Epoch 95: val_loss improved from 4200.33301 to 4050.88989, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4861.3169 - mae: 55.0979 - val_loss: 4050.8899 - val_mae: 52.1574\n",
      "Epoch 96/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4836.4043 - mae: 55.4025\n",
      "Epoch 96: val_loss improved from 4050.88989 to 3915.27051, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4738.3569 - mae: 54.6550 - val_loss: 3915.2705 - val_mae: 51.4148\n",
      "Epoch 97/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4370.1167 - mae: 52.2269\n",
      "Epoch 97: val_loss improved from 3915.27051 to 3792.18799, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4631.6748 - mae: 54.2635 - val_loss: 3792.1880 - val_mae: 50.7666\n",
      "Epoch 98/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4245.4170 - mae: 51.6196\n",
      "Epoch 98: val_loss improved from 3792.18799 to 3683.21533, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4530.1260 - mae: 53.9333 - val_loss: 3683.2153 - val_mae: 50.1733\n",
      "Epoch 99/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4707.6846 - mae: 55.4972\n",
      "Epoch 99: val_loss improved from 3683.21533 to 3581.85620, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4447.4639 - mae: 53.6945 - val_loss: 3581.8562 - val_mae: 49.6059\n",
      "Epoch 100/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4403.7422 - mae: 52.6859\n",
      "Epoch 100: val_loss improved from 3581.85620 to 3489.09790, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4365.1006 - mae: 53.4422 - val_loss: 3489.0979 - val_mae: 49.0595\n",
      "Epoch 101/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4371.3613 - mae: 53.8646\n",
      "Epoch 101: val_loss improved from 3489.09790 to 3403.17041, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4293.8623 - mae: 53.2180 - val_loss: 3403.1704 - val_mae: 48.5623\n",
      "Epoch 102/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4119.0845 - mae: 51.5561\n",
      "Epoch 102: val_loss improved from 3403.17041 to 3324.99194, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4228.3027 - mae: 53.0182 - val_loss: 3324.9919 - val_mae: 48.1142\n",
      "Epoch 103/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3781.3613 - mae: 49.9092\n",
      "Epoch 103: val_loss improved from 3324.99194 to 3255.28418, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4169.7686 - mae: 52.8571 - val_loss: 3255.2842 - val_mae: 47.7044\n",
      "Epoch 104/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4136.6123 - mae: 52.7546\n",
      "Epoch 104: val_loss improved from 3255.28418 to 3194.02661, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4118.8691 - mae: 52.6661 - val_loss: 3194.0266 - val_mae: 47.3223\n",
      "Epoch 105/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3902.6392 - mae: 51.4340\n",
      "Epoch 105: val_loss improved from 3194.02661 to 3140.77026, saving model to .\\best_model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 34ms/step - loss: 4076.2920 - mae: 52.5658 - val_loss: 3140.7703 - val_mae: 47.0482\n",
      "Epoch 106/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3518.8950 - mae: 49.4519\n",
      "Epoch 106: val_loss improved from 3140.77026 to 3094.63281, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4034.3484 - mae: 52.4146 - val_loss: 3094.6328 - val_mae: 46.7946\n",
      "Epoch 107/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4507.1982 - mae: 55.8529\n",
      "Epoch 107: val_loss improved from 3094.63281 to 3052.35083, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4006.1982 - mae: 52.3383 - val_loss: 3052.3508 - val_mae: 46.5473\n",
      "Epoch 108/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3737.3789 - mae: 51.7158\n",
      "Epoch 108: val_loss improved from 3052.35083 to 3017.95044, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 3972.7009 - mae: 52.2103 - val_loss: 3017.9504 - val_mae: 46.3423\n",
      "Epoch 109/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3838.8384 - mae: 51.5242\n",
      "Epoch 109: val_loss improved from 3017.95044 to 2987.88770, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3945.3162 - mae: 52.0911 - val_loss: 2987.8877 - val_mae: 46.1867\n",
      "Epoch 110/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4197.2954 - mae: 53.9499\n",
      "Epoch 110: val_loss improved from 2987.88770 to 2958.88184, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 3924.2266 - mae: 52.0217 - val_loss: 2958.8818 - val_mae: 46.0381\n",
      "Epoch 111/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3853.8818 - mae: 51.5150\n",
      "Epoch 111: val_loss improved from 2958.88184 to 2932.70801, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3904.1697 - mae: 51.9363 - val_loss: 2932.7080 - val_mae: 45.8959\n",
      "Epoch 112/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3609.2278 - mae: 50.2688\n",
      "Epoch 112: val_loss improved from 2932.70801 to 2910.41333, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3884.3059 - mae: 51.8635 - val_loss: 2910.4133 - val_mae: 45.7675\n",
      "Epoch 113/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4080.2422 - mae: 51.7043\n",
      "Epoch 113: val_loss improved from 2910.41333 to 2889.46631, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3870.0112 - mae: 51.8176 - val_loss: 2889.4663 - val_mae: 45.6412\n",
      "Epoch 114/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4254.5513 - mae: 54.3967\n",
      "Epoch 114: val_loss improved from 2889.46631 to 2872.20068, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3851.2617 - mae: 51.7186 - val_loss: 2872.2007 - val_mae: 45.5344\n",
      "Epoch 115/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4589.4307 - mae: 56.6655\n",
      "Epoch 115: val_loss improved from 2872.20068 to 2855.31958, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 3837.6196 - mae: 51.6405 - val_loss: 2855.3196 - val_mae: 45.4383\n",
      "Epoch 116/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3924.0898 - mae: 52.0317\n",
      "Epoch 116: val_loss improved from 2855.31958 to 2839.44141, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 3824.0771 - mae: 51.5750 - val_loss: 2839.4414 - val_mae: 45.3442\n",
      "Epoch 117/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3545.6631 - mae: 48.6987\n",
      "Epoch 117: val_loss improved from 2839.44141 to 2824.58423, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 3811.5312 - mae: 51.5104 - val_loss: 2824.5842 - val_mae: 45.2520\n",
      "Epoch 118/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3795.8401 - mae: 51.4520\n",
      "Epoch 118: val_loss improved from 2824.58423 to 2811.07764, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 3801.6492 - mae: 51.4568 - val_loss: 2811.0776 - val_mae: 45.1668\n",
      "Epoch 119/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4076.7661 - mae: 53.5311\n",
      "Epoch 119: val_loss improved from 2811.07764 to 2801.70898, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 3787.6433 - mae: 51.3770 - val_loss: 2801.7090 - val_mae: 45.1121\n",
      "Epoch 120/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3725.2275 - mae: 51.0795\n",
      "Epoch 120: val_loss improved from 2801.70898 to 2793.05664, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 3777.1526 - mae: 51.3064 - val_loss: 2793.0566 - val_mae: 45.0585\n",
      "Epoch 121/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3602.9414 - mae: 50.6919\n",
      "Epoch 121: val_loss improved from 2793.05664 to 2785.01367, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3766.8066 - mae: 51.2404 - val_loss: 2785.0137 - val_mae: 45.0072\n",
      "Epoch 122/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3991.5063 - mae: 51.6752\n",
      "Epoch 122: val_loss improved from 2785.01367 to 2778.04468, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3755.8408 - mae: 51.1619 - val_loss: 2778.0447 - val_mae: 44.9590\n",
      "Epoch 123/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3524.3264 - mae: 49.0792\n",
      "Epoch 123: val_loss improved from 2778.04468 to 2771.61865, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 3746.1516 - mae: 51.0949 - val_loss: 2771.6187 - val_mae: 44.9129\n",
      "Epoch 124/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3366.4175 - mae: 49.2916\n",
      "Epoch 124: val_loss improved from 2771.61865 to 2765.74878, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 3736.3726 - mae: 51.0263 - val_loss: 2765.7488 - val_mae: 44.8689\n",
      "Epoch 125/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3456.2246 - mae: 48.7022\n",
      "Epoch 125: val_loss improved from 2765.74878 to 2758.82251, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 3726.5691 - mae: 50.9595 - val_loss: 2758.8225 - val_mae: 44.8205\n",
      "Epoch 126/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3300.8149 - mae: 48.2390\n",
      "Epoch 126: val_loss improved from 2758.82251 to 2751.94043, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 3716.5022 - mae: 50.8934 - val_loss: 2751.9404 - val_mae: 44.7728\n",
      "Epoch 127/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3974.4705 - mae: 52.5747\n",
      "Epoch 127: val_loss improved from 2751.94043 to 2744.86133, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3707.4612 - mae: 50.8376 - val_loss: 2744.8613 - val_mae: 44.7243\n",
      "Epoch 128/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3710.3660 - mae: 51.7062\n",
      "Epoch 128: val_loss improved from 2744.86133 to 2738.12134, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3698.5046 - mae: 50.7839 - val_loss: 2738.1213 - val_mae: 44.6778\n",
      "Epoch 129/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3454.6694 - mae: 49.5239\n",
      "Epoch 129: val_loss improved from 2738.12134 to 2733.15845, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 3688.9570 - mae: 50.7163 - val_loss: 2733.1584 - val_mae: 44.6385\n",
      "Epoch 130/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3663.2368 - mae: 49.6067\n",
      "Epoch 130: val_loss improved from 2733.15845 to 2729.01392, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3680.0359 - mae: 50.6469 - val_loss: 2729.0139 - val_mae: 44.6020\n",
      "Epoch 131/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3356.3899 - mae: 47.7639\n",
      "Epoch 131: val_loss improved from 2729.01392 to 2723.45117, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3670.4692 - mae: 50.5721 - val_loss: 2723.4512 - val_mae: 44.5569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3840.5100 - mae: 53.1574\n",
      "Epoch 132: val_loss improved from 2723.45117 to 2717.43481, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3662.7659 - mae: 50.5167 - val_loss: 2717.4348 - val_mae: 44.5088\n",
      "Epoch 133/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4007.9897 - mae: 53.3726\n",
      "Epoch 133: val_loss improved from 2717.43481 to 2712.28296, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3653.4795 - mae: 50.4464 - val_loss: 2712.2830 - val_mae: 44.4632\n",
      "Epoch 134/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3749.3472 - mae: 50.8045\n",
      "Epoch 134: val_loss improved from 2712.28296 to 2707.60693, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 3644.2917 - mae: 50.3768 - val_loss: 2707.6069 - val_mae: 44.4208\n",
      "Epoch 135/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3466.5435 - mae: 50.7870\n",
      "Epoch 135: val_loss improved from 2707.60693 to 2701.46411, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3635.7861 - mae: 50.3127 - val_loss: 2701.4641 - val_mae: 44.3723\n",
      "Epoch 136/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3781.7051 - mae: 52.0482\n",
      "Epoch 136: val_loss improved from 2701.46411 to 2695.48340, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3627.5874 - mae: 50.2592 - val_loss: 2695.4834 - val_mae: 44.3241\n",
      "Epoch 137/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4061.6870 - mae: 54.4463\n",
      "Epoch 137: val_loss improved from 2695.48340 to 2690.22925, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3619.6528 - mae: 50.2038 - val_loss: 2690.2292 - val_mae: 44.2763\n",
      "Epoch 138/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3648.3286 - mae: 50.8513\n",
      "Epoch 138: val_loss improved from 2690.22925 to 2685.72217, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3610.1975 - mae: 50.1330 - val_loss: 2685.7222 - val_mae: 44.2343\n",
      "Epoch 139/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3686.2393 - mae: 50.1591\n",
      "Epoch 139: val_loss improved from 2685.72217 to 2681.24536, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3602.7275 - mae: 50.0772 - val_loss: 2681.2454 - val_mae: 44.1921\n",
      "Epoch 140/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3499.6533 - mae: 50.3013\n",
      "Epoch 140: val_loss improved from 2681.24536 to 2677.91089, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3593.8088 - mae: 50.0025 - val_loss: 2677.9109 - val_mae: 44.1554\n",
      "Epoch 141/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3470.7344 - mae: 48.1485\n",
      "Epoch 141: val_loss improved from 2677.91089 to 2674.79321, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3585.4946 - mae: 49.9302 - val_loss: 2674.7932 - val_mae: 44.1197\n",
      "Epoch 142/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3801.5159 - mae: 52.3741\n",
      "Epoch 142: val_loss improved from 2674.79321 to 2670.40405, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3578.1909 - mae: 49.8682 - val_loss: 2670.4041 - val_mae: 44.0770\n",
      "Epoch 143/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3368.3711 - mae: 47.8751\n",
      "Epoch 143: val_loss improved from 2670.40405 to 2666.98462, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 3569.6738 - mae: 49.7997 - val_loss: 2666.9846 - val_mae: 44.0401\n",
      "Epoch 144/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3152.5220 - mae: 46.3651\n",
      "Epoch 144: val_loss improved from 2666.98462 to 2663.40161, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 3561.9424 - mae: 49.7379 - val_loss: 2663.4016 - val_mae: 44.0031\n",
      "Epoch 145/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3619.4458 - mae: 51.2351\n",
      "Epoch 145: val_loss improved from 2663.40161 to 2660.59302, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 3554.1492 - mae: 49.6719 - val_loss: 2660.5930 - val_mae: 43.9693\n",
      "Epoch 146/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3349.8777 - mae: 48.3319\n",
      "Epoch 146: val_loss improved from 2660.59302 to 2658.63452, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3546.3938 - mae: 49.6028 - val_loss: 2658.6345 - val_mae: 43.9390\n",
      "Epoch 147/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3226.2888 - mae: 47.4009\n",
      "Epoch 147: val_loss improved from 2658.63452 to 2655.71777, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 3538.6450 - mae: 49.5328 - val_loss: 2655.7178 - val_mae: 43.9034\n",
      "Epoch 148/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3463.5059 - mae: 48.4244\n",
      "Epoch 148: val_loss improved from 2655.71777 to 2652.76489, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 3531.2954 - mae: 49.4685 - val_loss: 2652.7649 - val_mae: 43.8653\n",
      "Epoch 149/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3637.2654 - mae: 50.4235\n",
      "Epoch 149: val_loss improved from 2652.76489 to 2651.17188, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 3523.3359 - mae: 49.3939 - val_loss: 2651.1719 - val_mae: 43.8340\n",
      "Epoch 150/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3340.9534 - mae: 47.3226\n",
      "Epoch 150: val_loss improved from 2651.17188 to 2650.09814, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 3515.5984 - mae: 49.3188 - val_loss: 2650.0981 - val_mae: 43.8053\n",
      "Epoch 151/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3333.4583 - mae: 48.0953\n",
      "Epoch 151: val_loss improved from 2650.09814 to 2649.67236, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 3508.4341 - mae: 49.2439 - val_loss: 2649.6724 - val_mae: 43.7782\n",
      "Epoch 152/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3423.2395 - mae: 48.1531\n",
      "Epoch 152: val_loss improved from 2649.67236 to 2648.91870, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 3501.1641 - mae: 49.1663 - val_loss: 2648.9187 - val_mae: 43.7476\n",
      "Epoch 153/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3447.6938 - mae: 49.7056\n",
      "Epoch 153: val_loss improved from 2648.91870 to 2647.57715, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 3493.9666 - mae: 49.0866 - val_loss: 2647.5771 - val_mae: 43.7151\n",
      "Epoch 154/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3484.3262 - mae: 48.3789\n",
      "Epoch 154: val_loss improved from 2647.57715 to 2643.95850, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 3487.2764 - mae: 49.0184 - val_loss: 2643.9585 - val_mae: 43.6730\n",
      "Epoch 155/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3549.1064 - mae: 48.0843\n",
      "Epoch 155: val_loss improved from 2643.95850 to 2641.46313, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3479.2954 - mae: 48.9517 - val_loss: 2641.4631 - val_mae: 43.6367\n",
      "Epoch 156/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3236.9922 - mae: 45.9690\n",
      "Epoch 156: val_loss improved from 2641.46313 to 2639.17725, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 3472.3542 - mae: 48.8877 - val_loss: 2639.1772 - val_mae: 43.5986\n",
      "Epoch 157/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3820.3096 - mae: 51.6017\n",
      "Epoch 157: val_loss improved from 2639.17725 to 2638.11572, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 3465.2229 - mae: 48.8171 - val_loss: 2638.1157 - val_mae: 43.5674\n",
      "Epoch 158/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3430.8049 - mae: 49.2004\n",
      "Epoch 158: val_loss improved from 2638.11572 to 2635.91431, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 3458.2864 - mae: 48.7492 - val_loss: 2635.9143 - val_mae: 43.5302\n",
      "Epoch 159/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3813.9255 - mae: 51.1218\n",
      "Epoch 159: val_loss improved from 2635.91431 to 2632.16138, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 3451.5085 - mae: 48.6848 - val_loss: 2632.1614 - val_mae: 43.4873\n",
      "Epoch 160/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4305.1577 - mae: 56.2918\n",
      "Epoch 160: val_loss improved from 2632.16138 to 2629.01562, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 3444.5596 - mae: 48.6280 - val_loss: 2629.0156 - val_mae: 43.4480\n",
      "Epoch 161/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3369.1838 - mae: 48.3727\n",
      "Epoch 161: val_loss improved from 2629.01562 to 2627.16699, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3437.7734 - mae: 48.5670 - val_loss: 2627.1670 - val_mae: 43.4140\n",
      "Epoch 162/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3007.1108 - mae: 45.7874\n",
      "Epoch 162: val_loss improved from 2627.16699 to 2623.83350, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 3430.4473 - mae: 48.5076 - val_loss: 2623.8335 - val_mae: 43.3739\n",
      "Epoch 163/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3797.6582 - mae: 50.7138\n",
      "Epoch 163: val_loss improved from 2623.83350 to 2620.48071, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3424.5056 - mae: 48.4610 - val_loss: 2620.4807 - val_mae: 43.3335\n",
      "Epoch 164/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3790.7896 - mae: 51.3813\n",
      "Epoch 164: val_loss improved from 2620.48071 to 2618.02075, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3417.6072 - mae: 48.4039 - val_loss: 2618.0208 - val_mae: 43.2994\n",
      "Epoch 165/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 4050.7915 - mae: 52.1395\n",
      "Epoch 165: val_loss improved from 2618.02075 to 2614.89673, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3411.3364 - mae: 48.3608 - val_loss: 2614.8967 - val_mae: 43.2614\n",
      "Epoch 166/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3825.2830 - mae: 51.4371\n",
      "Epoch 166: val_loss improved from 2614.89673 to 2612.75293, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3405.0864 - mae: 48.3146 - val_loss: 2612.7529 - val_mae: 43.2269\n",
      "Epoch 167/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3650.2407 - mae: 50.8454\n",
      "Epoch 167: val_loss improved from 2612.75293 to 2612.22852, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 3398.5991 - mae: 48.2582 - val_loss: 2612.2285 - val_mae: 43.2072\n",
      "Epoch 168/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3974.5593 - mae: 53.1552\n",
      "Epoch 168: val_loss improved from 2612.22852 to 2611.39697, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 3392.2571 - mae: 48.1947 - val_loss: 2611.3970 - val_mae: 43.1858\n",
      "Epoch 169/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3275.5791 - mae: 46.0244\n",
      "Epoch 169: val_loss improved from 2611.39697 to 2611.05493, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 3386.1067 - mae: 48.1371 - val_loss: 2611.0549 - val_mae: 43.1667\n",
      "Epoch 170/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3335.0735 - mae: 48.9474\n",
      "Epoch 170: val_loss did not improve from 2611.05493\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3379.9595 - mae: 48.0735 - val_loss: 2612.1001 - val_mae: 43.1565\n",
      "Epoch 171/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3299.0791 - mae: 46.8834\n",
      "Epoch 171: val_loss did not improve from 2611.05493\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3374.1777 - mae: 48.0099 - val_loss: 2612.1316 - val_mae: 43.1405\n",
      "Epoch 172/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3545.2839 - mae: 48.2789\n",
      "Epoch 172: val_loss did not improve from 2611.05493\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3368.1931 - mae: 47.9488 - val_loss: 2611.1646 - val_mae: 43.1243\n",
      "Epoch 173/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3374.2791 - mae: 49.0448\n",
      "Epoch 173: val_loss improved from 2611.05493 to 2609.80493, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 3362.1355 - mae: 47.8962 - val_loss: 2609.8049 - val_mae: 43.1062\n",
      "Epoch 174/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3589.2031 - mae: 48.7551\n",
      "Epoch 174: val_loss improved from 2609.80493 to 2607.88110, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 3356.4255 - mae: 47.8489 - val_loss: 2607.8811 - val_mae: 43.0846\n",
      "Epoch 175/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3419.8445 - mae: 47.9900\n",
      "Epoch 175: val_loss improved from 2607.88110 to 2606.75073, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3350.6311 - mae: 47.7983 - val_loss: 2606.7507 - val_mae: 43.0665\n",
      "Epoch 176/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3313.6094 - mae: 46.8281\n",
      "Epoch 176: val_loss improved from 2606.75073 to 2604.78931, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3344.6111 - mae: 47.7461 - val_loss: 2604.7893 - val_mae: 43.0427\n",
      "Epoch 177/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3616.2817 - mae: 50.2836\n",
      "Epoch 177: val_loss improved from 2604.78931 to 2602.82422, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 3338.6450 - mae: 47.6965 - val_loss: 2602.8242 - val_mae: 43.0187\n",
      "Epoch 178/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3214.9795 - mae: 46.3382\n",
      "Epoch 178: val_loss improved from 2602.82422 to 2601.72949, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 3333.0178 - mae: 47.6463 - val_loss: 2601.7295 - val_mae: 42.9995\n",
      "Epoch 179/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3086.9678 - mae: 45.6692\n",
      "Epoch 179: val_loss improved from 2601.72949 to 2600.61597, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 3327.4109 - mae: 47.5939 - val_loss: 2600.6160 - val_mae: 42.9805\n",
      "Epoch 180/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3444.7957 - mae: 48.0205\n",
      "Epoch 180: val_loss improved from 2600.61597 to 2598.15503, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3321.7341 - mae: 47.5481 - val_loss: 2598.1550 - val_mae: 42.9523\n",
      "Epoch 181/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3296.6431 - mae: 46.9304\n",
      "Epoch 181: val_loss improved from 2598.15503 to 2594.99927, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3315.8774 - mae: 47.5087 - val_loss: 2594.9993 - val_mae: 42.9188\n",
      "Epoch 182/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3512.9885 - mae: 48.7850\n",
      "Epoch 182: val_loss improved from 2594.99927 to 2592.50659, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3310.7197 - mae: 47.4723 - val_loss: 2592.5066 - val_mae: 42.8906\n",
      "Epoch 183/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3421.9536 - mae: 49.5522\n",
      "Epoch 183: val_loss improved from 2592.50659 to 2589.63574, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3304.4543 - mae: 47.4319 - val_loss: 2589.6357 - val_mae: 42.8595\n",
      "Epoch 184/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3320.4702 - mae: 46.6965\n",
      "Epoch 184: val_loss improved from 2589.63574 to 2587.02954, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3299.0703 - mae: 47.3923 - val_loss: 2587.0295 - val_mae: 42.8299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 185/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3200.4302 - mae: 45.8548\n",
      "Epoch 185: val_loss improved from 2587.02954 to 2584.68530, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3293.4495 - mae: 47.3527 - val_loss: 2584.6853 - val_mae: 42.8019\n",
      "Epoch 186/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2999.2231 - mae: 45.1758\n",
      "Epoch 186: val_loss improved from 2584.68530 to 2582.14429, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3288.3188 - mae: 47.3156 - val_loss: 2582.1443 - val_mae: 42.7714\n",
      "Epoch 187/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3726.7378 - mae: 50.6686\n",
      "Epoch 187: val_loss improved from 2582.14429 to 2580.61841, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3283.2024 - mae: 47.2760 - val_loss: 2580.6184 - val_mae: 42.7486\n",
      "Epoch 188/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2896.7061 - mae: 44.6189\n",
      "Epoch 188: val_loss improved from 2580.61841 to 2579.39819, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3277.7834 - mae: 47.2285 - val_loss: 2579.3982 - val_mae: 42.7276\n",
      "Epoch 189/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3200.2297 - mae: 46.7415\n",
      "Epoch 189: val_loss improved from 2579.39819 to 2577.56738, saving model to .\\best_model.h5\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3272.8184 - mae: 47.1912 - val_loss: 2577.5674 - val_mae: 42.7015\n",
      "Epoch 190/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3222.6348 - mae: 46.8590\n",
      "Epoch 190: val_loss did not improve from 2577.56738\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3267.2793 - mae: 47.1428 - val_loss: 2577.9666 - val_mae: 42.6921\n",
      "Epoch 191/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3356.7188 - mae: 47.6904\n",
      "Epoch 191: val_loss did not improve from 2577.56738\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3262.2698 - mae: 47.0916 - val_loss: 2578.0859 - val_mae: 42.6809\n",
      "Epoch 192/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 2586.7437 - mae: 41.8323\n",
      "Epoch 192: val_loss did not improve from 2577.56738\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3256.7380 - mae: 47.0373 - val_loss: 2579.7263 - val_mae: 42.6796\n",
      "Epoch 193/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3193.4744 - mae: 47.0953\n",
      "Epoch 193: val_loss did not improve from 2577.56738\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3252.1587 - mae: 46.9786 - val_loss: 2581.7749 - val_mae: 42.6808\n",
      "Epoch 194/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 3293.0103 - mae: 47.4168\n",
      "Epoch 194: val_loss did not improve from 2577.56738\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3246.8438 - mae: 46.9159 - val_loss: 2583.5088 - val_mae: 42.6800\n",
      "Epoch 194: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, \n",
    "          epochs = 1000, batch_size = 128,\n",
    "          validation_split=0.2, callbacks=[es, mc], verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdcb2ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'mae')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mae'])\n",
    "plt.plot(history.history['val_mae'])\n",
    "plt.title('Training mae')\n",
    "plt.legend(['mae', 'val_mae'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b58cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
