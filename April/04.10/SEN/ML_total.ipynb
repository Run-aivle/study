{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7303d7e1",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f25775ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cde792fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3af00da",
   "metadata": {},
   "source": [
    "</br>\n",
    "1-1 <font color=red> pd.read_csv</font>로 일반적으로 가지고 있는 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bf0c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['data'], columns = data['feature_names'])\n",
    "df['target'] = data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ba8d5b",
   "metadata": {},
   "source": [
    "### 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fc4fda",
   "metadata": {},
   "source": [
    "</br>\n",
    "2-1 데이터프레임 앞부분 3줄, 뒷부분 3줄을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f93390",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0          0.11840   \n",
       "1        20.57         17.77           132.9     1326.0          0.08474   \n",
       "2        19.69         21.25           130.0     1203.0          0.10960   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33            184.6      2019.0   \n",
       "1                 0.05667  ...          23.41            158.8      1956.0   \n",
       "2                 0.05999  ...          25.53            152.5      1709.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f09f5f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "566                0.1418          0.2218                  0.07820       0  \n",
       "567                0.2650          0.4087                  0.12400       0  \n",
       "568                0.0000          0.2871                  0.07039       1  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb08af1",
   "metadata": {},
   "source": [
    "</br>\n",
    "2-2 데이퍼프레임 정보를 출력하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41cc4a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  target                   569 non-null    int32  \n",
      "dtypes: float64(30), int32(1)\n",
      "memory usage: 135.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bdf873",
   "metadata": {},
   "source": [
    "</br>\n",
    "2-3 데이터프레임 인덱스를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "322bfb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=569, step=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a4aa27",
   "metadata": {},
   "source": [
    "</br>\n",
    "2-4 데이터프레임 컬럼 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "873f76dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
       "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
       "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
       "       'worst concave points', 'worst symmetry', 'worst fractal dimension',\n",
       "       'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b6379f",
   "metadata": {},
   "source": [
    "</br>\n",
    "2-5 데이터프레임 값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd15f2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 4.601e-01, 1.189e-01,\n",
       "        0.000e+00],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 2.750e-01, 8.902e-02,\n",
       "        0.000e+00],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 3.613e-01, 8.758e-02,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 2.218e-01, 7.820e-02,\n",
       "        0.000e+00],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 4.087e-01, 1.240e-01,\n",
       "        0.000e+00],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 2.871e-01, 7.039e-02,\n",
       "        1.000e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43e16ed",
   "metadata": {},
   "source": [
    "</br>\n",
    "2-6 데이터프레임의 계산 가능한 값들에 대한 통계치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f2947a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       "count     569.000000              569.000000  ...     569.000000   \n",
       "mean        0.181162                0.062798  ...      25.677223   \n",
       "std         0.027414                0.007060  ...       6.146258   \n",
       "min         0.106000                0.049960  ...      12.020000   \n",
       "25%         0.161900                0.057700  ...      21.080000   \n",
       "50%         0.179200                0.061540  ...      25.410000   \n",
       "75%         0.195700                0.066120  ...      29.720000   \n",
       "max         0.304000                0.097440  ...      49.540000   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       worst fractal dimension      target  \n",
       "count               569.000000  569.000000  \n",
       "mean                  0.083946    0.627417  \n",
       "std                   0.018061    0.483918  \n",
       "min                   0.055040    0.000000  \n",
       "25%                   0.071460    0.000000  \n",
       "50%                   0.080040    1.000000  \n",
       "75%                   0.092080    1.000000  \n",
       "max                   0.207500    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca2f78",
   "metadata": {},
   "source": [
    "<br/> \n",
    "2-7 데이터프레임 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7a4b4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0\n",
       "mean texture               0\n",
       "mean perimeter             0\n",
       "mean area                  0\n",
       "mean smoothness            0\n",
       "mean compactness           0\n",
       "mean concavity             0\n",
       "mean concave points        0\n",
       "mean symmetry              0\n",
       "mean fractal dimension     0\n",
       "radius error               0\n",
       "texture error              0\n",
       "perimeter error            0\n",
       "area error                 0\n",
       "smoothness error           0\n",
       "compactness error          0\n",
       "concavity error            0\n",
       "concave points error       0\n",
       "symmetry error             0\n",
       "fractal dimension error    0\n",
       "worst radius               0\n",
       "worst texture              0\n",
       "worst perimeter            0\n",
       "worst area                 0\n",
       "worst smoothness           0\n",
       "worst compactness          0\n",
       "worst concavity            0\n",
       "worst concave points       0\n",
       "worst symmetry             0\n",
       "worst fractal dimension    0\n",
       "target                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eb888a",
   "metadata": {},
   "source": [
    "</br>\n",
    "2-8 'target'컬럼 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62123d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "564    0\n",
       "565    0\n",
       "566    0\n",
       "567    0\n",
       "568    1\n",
       "Name: target, Length: 569, dtype: int32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb03506",
   "metadata": {},
   "source": [
    "</br>\n",
    "2-9 'target' 컬럼의 데이터별 건수와 비율 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2904c159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    357\n",
      "0    212\n",
      "Name: target, dtype: int64\n",
      "1    0.627417\n",
      "0    0.372583\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['target'].value_counts())\n",
    "print(df['target'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd82359",
   "metadata": {},
   "source": [
    "</br>\n",
    "2-10 모든 컬럼 데이터별 건수와 비율 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68124469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.34    4\n",
      "11.71    3\n",
      "12.46    3\n",
      "13.05    3\n",
      "10.26    3\n",
      "        ..\n",
      "12.23    1\n",
      "14.45    1\n",
      "19.18    1\n",
      "18.08    1\n",
      "7.76     1\n",
      "Name: mean radius, Length: 456, dtype: int64, 20.52    3\n",
      "16.85    3\n",
      "16.84    3\n",
      "19.83    3\n",
      "14.93    3\n",
      "        ..\n",
      "18.58    1\n",
      "15.11    1\n",
      "22.41    1\n",
      "14.92    1\n",
      "24.54    1\n",
      "Name: mean texture, Length: 479, dtype: int64, 82.61     3\n",
      "87.76     3\n",
      "134.70    3\n",
      "93.97     2\n",
      "82.69     2\n",
      "         ..\n",
      "127.50    1\n",
      "90.63     1\n",
      "82.53     1\n",
      "100.40    1\n",
      "47.92     1\n",
      "Name: mean perimeter, Length: 522, dtype: int64, 512.2     3\n",
      "1075.0    2\n",
      "582.7     2\n",
      "399.8     2\n",
      "641.2     2\n",
      "         ..\n",
      "507.4     1\n",
      "609.9     1\n",
      "463.7     1\n",
      "428.9     1\n",
      "181.0     1\n",
      "Name: mean area, Length: 539, dtype: int64, 0.10070    5\n",
      "0.11500    4\n",
      "0.10540    4\n",
      "0.10750    4\n",
      "0.10630    3\n",
      "          ..\n",
      "0.08876    1\n",
      "0.09965    1\n",
      "0.13230    1\n",
      "0.08968    1\n",
      "0.05263    1\n",
      "Name: mean smoothness, Length: 474, dtype: int64, 0.11470    3\n",
      "0.12060    3\n",
      "0.07698    2\n",
      "0.05743    2\n",
      "0.03834    2\n",
      "          ..\n",
      "0.05562    1\n",
      "0.06141    1\n",
      "0.04695    1\n",
      "0.10520    1\n",
      "0.04362    1\n",
      "Name: mean compactness, Length: 537, dtype: int64, 0.000000    13\n",
      "0.120400     3\n",
      "0.111500     2\n",
      "0.033440     2\n",
      "0.110300     2\n",
      "            ..\n",
      "0.065930     1\n",
      "0.248700     1\n",
      "0.287100     1\n",
      "0.009193     1\n",
      "0.351400     1\n",
      "Name: mean concavity, Length: 537, dtype: int64, 0.00000    13\n",
      "0.02864     3\n",
      "0.14710     2\n",
      "0.05778     2\n",
      "0.02272     2\n",
      "           ..\n",
      "0.02361     1\n",
      "0.05189     1\n",
      "0.14960     1\n",
      "0.18780     1\n",
      "0.15200     1\n",
      "Name: mean concave points, Length: 542, dtype: int64, 0.1714    4\n",
      "0.1769    4\n",
      "0.1893    4\n",
      "0.1601    4\n",
      "0.1717    4\n",
      "         ..\n",
      "0.2251    1\n",
      "0.2200    1\n",
      "0.1979    1\n",
      "0.1950    1\n",
      "0.1587    1\n",
      "Name: mean symmetry, Length: 432, dtype: int64, 0.06113    3\n",
      "0.05913    3\n",
      "0.05907    3\n",
      "0.05667    3\n",
      "0.06782    3\n",
      "          ..\n",
      "0.05234    1\n",
      "0.06323    1\n",
      "0.08116    1\n",
      "0.05975    1\n",
      "0.07016    1\n",
      "Name: mean fractal dimension, Length: 499, dtype: int64, 0.2860    3\n",
      "0.2204    3\n",
      "0.2684    2\n",
      "0.2239    2\n",
      "0.1601    2\n",
      "         ..\n",
      "0.6298    1\n",
      "0.8361    1\n",
      "0.2889    1\n",
      "0.1731    1\n",
      "0.3857    1\n",
      "Name: radius error, Length: 540, dtype: int64, 1.1500    3\n",
      "1.3500    3\n",
      "1.2680    3\n",
      "0.8561    3\n",
      "1.0160    2\n",
      "         ..\n",
      "0.7655    1\n",
      "0.4757    1\n",
      "0.4956    1\n",
      "0.7629    1\n",
      "1.5950    1\n",
      "Name: texture error, Length: 519, dtype: int64, 1.778    4\n",
      "1.243    2\n",
      "2.569    2\n",
      "2.183    2\n",
      "3.008    2\n",
      "        ..\n",
      "2.112    1\n",
      "1.687    1\n",
      "1.011    1\n",
      "1.742    1\n",
      "2.548    1\n",
      "Name: perimeter error, Length: 533, dtype: int64, 16.97    3\n",
      "17.67    3\n",
      "16.64    3\n",
      "18.54    3\n",
      "20.98    2\n",
      "        ..\n",
      "26.43    1\n",
      "22.77    1\n",
      "40.98    1\n",
      "81.46    1\n",
      "19.15    1\n",
      "Name: area error, Length: 528, dtype: int64, 0.006399    2\n",
      "0.010520    2\n",
      "0.012910    2\n",
      "0.007189    2\n",
      "0.005298    2\n",
      "           ..\n",
      "0.006905    1\n",
      "0.002866    1\n",
      "0.014390    1\n",
      "0.003290    1\n",
      "0.006522    1\n",
      "Name: smoothness error, Length: 547, dtype: int64, 0.01812    3\n",
      "0.02310    3\n",
      "0.01104    3\n",
      "0.02431    2\n",
      "0.01203    2\n",
      "          ..\n",
      "0.01200    1\n",
      "0.03728    1\n",
      "0.02263    1\n",
      "0.04759    1\n",
      "0.00466    1\n",
      "Name: compactness error, Length: 541, dtype: int64, 0.000000    13\n",
      "0.016520     2\n",
      "0.016980     2\n",
      "0.026810     2\n",
      "0.035760     2\n",
      "            ..\n",
      "0.015560     1\n",
      "0.019780     1\n",
      "0.001597     1\n",
      "0.017740     1\n",
      "0.071170     1\n",
      "Name: concavity error, Length: 533, dtype: int64, 0.00000    13\n",
      "0.01167     3\n",
      "0.01110     3\n",
      "0.01499     3\n",
      "0.01004     2\n",
      "           ..\n",
      "0.00842     1\n",
      "0.01883     1\n",
      "0.01321     1\n",
      "0.01757     1\n",
      "0.01664     1\n",
      "Name: concave points error, Length: 507, dtype: int64, 0.01344    4\n",
      "0.02045    3\n",
      "0.01884    3\n",
      "0.01647    3\n",
      "0.01870    3\n",
      "          ..\n",
      "0.02538    1\n",
      "0.01172    1\n",
      "0.01613    1\n",
      "0.01682    1\n",
      "0.02676    1\n",
      "Name: symmetry error, Length: 498, dtype: int64, 0.004005    2\n",
      "0.003224    2\n",
      "0.004560    2\n",
      "0.005667    2\n",
      "0.001892    2\n",
      "           ..\n",
      "0.001988    1\n",
      "0.001671    1\n",
      "0.001087    1\n",
      "0.003470    1\n",
      "0.006185    1\n",
      "Name: fractal dimension error, Length: 545, dtype: int64, 12.360    5\n",
      "13.340    4\n",
      "13.500    4\n",
      "12.840    3\n",
      "15.140    3\n",
      "         ..\n",
      "15.740    1\n",
      "11.870    1\n",
      "17.800    1\n",
      "12.370    1\n",
      "9.456     1\n",
      "Name: worst radius, Length: 457, dtype: int64, 27.26    3\n",
      "17.70    3\n",
      "16.93    2\n",
      "30.50    2\n",
      "23.17    2\n",
      "        ..\n",
      "32.06    1\n",
      "24.70    1\n",
      "22.00    1\n",
      "39.34    1\n",
      "30.37    1\n",
      "Name: worst texture, Length: 511, dtype: int64, 117.70    3\n",
      "105.90    3\n",
      "101.70    3\n",
      "184.60    2\n",
      "106.40    2\n",
      "         ..\n",
      "79.57     1\n",
      "84.42     1\n",
      "139.20    1\n",
      "75.39     1\n",
      "59.16     1\n",
      "Name: worst perimeter, Length: 514, dtype: int64, 472.4     2\n",
      "1210.0    2\n",
      "826.4     2\n",
      "402.8     2\n",
      "1750.0    2\n",
      "         ..\n",
      "579.5     1\n",
      "762.4     1\n",
      "521.5     1\n",
      "1410.0    1\n",
      "268.6     1\n",
      "Name: worst area, Length: 544, dtype: int64, 0.13470    4\n",
      "0.12750    4\n",
      "0.12230    4\n",
      "0.14010    4\n",
      "0.12340    4\n",
      "          ..\n",
      "0.22260    1\n",
      "0.13810    1\n",
      "0.14290    1\n",
      "0.13220    1\n",
      "0.08996    1\n",
      "Name: worst smoothness, Length: 411, dtype: int64, 0.34160    3\n",
      "0.14860    3\n",
      "0.21700    2\n",
      "0.09866    2\n",
      "0.22640    2\n",
      "          ..\n",
      "0.24450    1\n",
      "0.10190    1\n",
      "0.32990    1\n",
      "0.16100    1\n",
      "0.06444    1\n",
      "Name: worst compactness, Length: 529, dtype: int64, 0.00000    13\n",
      "0.45040     3\n",
      "0.13770     3\n",
      "0.18040     2\n",
      "0.18110     2\n",
      "           ..\n",
      "0.00692     1\n",
      "0.16480     1\n",
      "0.29020     1\n",
      "0.67800     1\n",
      "0.93870     1\n",
      "Name: worst concavity, Length: 539, dtype: int64, 0.00000    13\n",
      "0.05556     3\n",
      "0.06296     3\n",
      "0.12180     3\n",
      "0.07431     3\n",
      "           ..\n",
      "0.15410     1\n",
      "0.29030     1\n",
      "0.26880     1\n",
      "0.03990     1\n",
      "0.26500     1\n",
      "Name: worst concave points, Length: 492, dtype: int64, 0.2226    3\n",
      "0.2369    3\n",
      "0.2972    3\n",
      "0.3196    3\n",
      "0.3109    3\n",
      "         ..\n",
      "0.3024    1\n",
      "0.3000    1\n",
      "0.3215    1\n",
      "0.1909    1\n",
      "0.4087    1\n",
      "Name: worst symmetry, Length: 500, dtype: int64, 0.07427    3\n",
      "0.09026    2\n",
      "0.12970    2\n",
      "0.08174    2\n",
      "0.10550    2\n",
      "          ..\n",
      "0.06938    1\n",
      "0.07697    1\n",
      "0.09772    1\n",
      "0.08631    1\n",
      "0.07039    1\n",
      "Name: worst fractal dimension, Length: 535, dtype: int64, 1    357\n",
      "0    212\n",
      "Name: target, dtype: int64]\n",
      "[12.34    0.007030\n",
      "11.71    0.005272\n",
      "12.46    0.005272\n",
      "13.05    0.005272\n",
      "10.26    0.005272\n",
      "           ...   \n",
      "12.23    0.001757\n",
      "14.45    0.001757\n",
      "19.18    0.001757\n",
      "18.08    0.001757\n",
      "7.76     0.001757\n",
      "Name: mean radius, Length: 456, dtype: float64, 20.52    0.005272\n",
      "16.85    0.005272\n",
      "16.84    0.005272\n",
      "19.83    0.005272\n",
      "14.93    0.005272\n",
      "           ...   \n",
      "18.58    0.001757\n",
      "15.11    0.001757\n",
      "22.41    0.001757\n",
      "14.92    0.001757\n",
      "24.54    0.001757\n",
      "Name: mean texture, Length: 479, dtype: float64, 82.61     0.005272\n",
      "87.76     0.005272\n",
      "134.70    0.005272\n",
      "93.97     0.003515\n",
      "82.69     0.003515\n",
      "            ...   \n",
      "127.50    0.001757\n",
      "90.63     0.001757\n",
      "82.53     0.001757\n",
      "100.40    0.001757\n",
      "47.92     0.001757\n",
      "Name: mean perimeter, Length: 522, dtype: float64, 512.2     0.005272\n",
      "1075.0    0.003515\n",
      "582.7     0.003515\n",
      "399.8     0.003515\n",
      "641.2     0.003515\n",
      "            ...   \n",
      "507.4     0.001757\n",
      "609.9     0.001757\n",
      "463.7     0.001757\n",
      "428.9     0.001757\n",
      "181.0     0.001757\n",
      "Name: mean area, Length: 539, dtype: float64, 0.10070    0.008787\n",
      "0.11500    0.007030\n",
      "0.10540    0.007030\n",
      "0.10750    0.007030\n",
      "0.10630    0.005272\n",
      "             ...   \n",
      "0.08876    0.001757\n",
      "0.09965    0.001757\n",
      "0.13230    0.001757\n",
      "0.08968    0.001757\n",
      "0.05263    0.001757\n",
      "Name: mean smoothness, Length: 474, dtype: float64, 0.11470    0.005272\n",
      "0.12060    0.005272\n",
      "0.07698    0.003515\n",
      "0.05743    0.003515\n",
      "0.03834    0.003515\n",
      "             ...   \n",
      "0.05562    0.001757\n",
      "0.06141    0.001757\n",
      "0.04695    0.001757\n",
      "0.10520    0.001757\n",
      "0.04362    0.001757\n",
      "Name: mean compactness, Length: 537, dtype: float64, 0.000000    0.022847\n",
      "0.120400    0.005272\n",
      "0.111500    0.003515\n",
      "0.033440    0.003515\n",
      "0.110300    0.003515\n",
      "              ...   \n",
      "0.065930    0.001757\n",
      "0.248700    0.001757\n",
      "0.287100    0.001757\n",
      "0.009193    0.001757\n",
      "0.351400    0.001757\n",
      "Name: mean concavity, Length: 537, dtype: float64, 0.00000    0.022847\n",
      "0.02864    0.005272\n",
      "0.14710    0.003515\n",
      "0.05778    0.003515\n",
      "0.02272    0.003515\n",
      "             ...   \n",
      "0.02361    0.001757\n",
      "0.05189    0.001757\n",
      "0.14960    0.001757\n",
      "0.18780    0.001757\n",
      "0.15200    0.001757\n",
      "Name: mean concave points, Length: 542, dtype: float64, 0.1714    0.007030\n",
      "0.1769    0.007030\n",
      "0.1893    0.007030\n",
      "0.1601    0.007030\n",
      "0.1717    0.007030\n",
      "            ...   \n",
      "0.2251    0.001757\n",
      "0.2200    0.001757\n",
      "0.1979    0.001757\n",
      "0.1950    0.001757\n",
      "0.1587    0.001757\n",
      "Name: mean symmetry, Length: 432, dtype: float64, 0.06113    0.005272\n",
      "0.05913    0.005272\n",
      "0.05907    0.005272\n",
      "0.05667    0.005272\n",
      "0.06782    0.005272\n",
      "             ...   \n",
      "0.05234    0.001757\n",
      "0.06323    0.001757\n",
      "0.08116    0.001757\n",
      "0.05975    0.001757\n",
      "0.07016    0.001757\n",
      "Name: mean fractal dimension, Length: 499, dtype: float64, 0.2860    0.005272\n",
      "0.2204    0.005272\n",
      "0.2684    0.003515\n",
      "0.2239    0.003515\n",
      "0.1601    0.003515\n",
      "            ...   \n",
      "0.6298    0.001757\n",
      "0.8361    0.001757\n",
      "0.2889    0.001757\n",
      "0.1731    0.001757\n",
      "0.3857    0.001757\n",
      "Name: radius error, Length: 540, dtype: float64, 1.1500    0.005272\n",
      "1.3500    0.005272\n",
      "1.2680    0.005272\n",
      "0.8561    0.005272\n",
      "1.0160    0.003515\n",
      "            ...   \n",
      "0.7655    0.001757\n",
      "0.4757    0.001757\n",
      "0.4956    0.001757\n",
      "0.7629    0.001757\n",
      "1.5950    0.001757\n",
      "Name: texture error, Length: 519, dtype: float64, 1.778    0.007030\n",
      "1.243    0.003515\n",
      "2.569    0.003515\n",
      "2.183    0.003515\n",
      "3.008    0.003515\n",
      "           ...   \n",
      "2.112    0.001757\n",
      "1.687    0.001757\n",
      "1.011    0.001757\n",
      "1.742    0.001757\n",
      "2.548    0.001757\n",
      "Name: perimeter error, Length: 533, dtype: float64, 16.97    0.005272\n",
      "17.67    0.005272\n",
      "16.64    0.005272\n",
      "18.54    0.005272\n",
      "20.98    0.003515\n",
      "           ...   \n",
      "26.43    0.001757\n",
      "22.77    0.001757\n",
      "40.98    0.001757\n",
      "81.46    0.001757\n",
      "19.15    0.001757\n",
      "Name: area error, Length: 528, dtype: float64, 0.006399    0.003515\n",
      "0.010520    0.003515\n",
      "0.012910    0.003515\n",
      "0.007189    0.003515\n",
      "0.005298    0.003515\n",
      "              ...   \n",
      "0.006905    0.001757\n",
      "0.002866    0.001757\n",
      "0.014390    0.001757\n",
      "0.003290    0.001757\n",
      "0.006522    0.001757\n",
      "Name: smoothness error, Length: 547, dtype: float64, 0.01812    0.005272\n",
      "0.02310    0.005272\n",
      "0.01104    0.005272\n",
      "0.02431    0.003515\n",
      "0.01203    0.003515\n",
      "             ...   \n",
      "0.01200    0.001757\n",
      "0.03728    0.001757\n",
      "0.02263    0.001757\n",
      "0.04759    0.001757\n",
      "0.00466    0.001757\n",
      "Name: compactness error, Length: 541, dtype: float64, 0.000000    0.022847\n",
      "0.016520    0.003515\n",
      "0.016980    0.003515\n",
      "0.026810    0.003515\n",
      "0.035760    0.003515\n",
      "              ...   \n",
      "0.015560    0.001757\n",
      "0.019780    0.001757\n",
      "0.001597    0.001757\n",
      "0.017740    0.001757\n",
      "0.071170    0.001757\n",
      "Name: concavity error, Length: 533, dtype: float64, 0.00000    0.022847\n",
      "0.01167    0.005272\n",
      "0.01110    0.005272\n",
      "0.01499    0.005272\n",
      "0.01004    0.003515\n",
      "             ...   \n",
      "0.00842    0.001757\n",
      "0.01883    0.001757\n",
      "0.01321    0.001757\n",
      "0.01757    0.001757\n",
      "0.01664    0.001757\n",
      "Name: concave points error, Length: 507, dtype: float64, 0.01344    0.007030\n",
      "0.02045    0.005272\n",
      "0.01884    0.005272\n",
      "0.01647    0.005272\n",
      "0.01870    0.005272\n",
      "             ...   \n",
      "0.02538    0.001757\n",
      "0.01172    0.001757\n",
      "0.01613    0.001757\n",
      "0.01682    0.001757\n",
      "0.02676    0.001757\n",
      "Name: symmetry error, Length: 498, dtype: float64, 0.004005    0.003515\n",
      "0.003224    0.003515\n",
      "0.004560    0.003515\n",
      "0.005667    0.003515\n",
      "0.001892    0.003515\n",
      "              ...   \n",
      "0.001988    0.001757\n",
      "0.001671    0.001757\n",
      "0.001087    0.001757\n",
      "0.003470    0.001757\n",
      "0.006185    0.001757\n",
      "Name: fractal dimension error, Length: 545, dtype: float64, 12.360    0.008787\n",
      "13.340    0.007030\n",
      "13.500    0.007030\n",
      "12.840    0.005272\n",
      "15.140    0.005272\n",
      "            ...   \n",
      "15.740    0.001757\n",
      "11.870    0.001757\n",
      "17.800    0.001757\n",
      "12.370    0.001757\n",
      "9.456     0.001757\n",
      "Name: worst radius, Length: 457, dtype: float64, 27.26    0.005272\n",
      "17.70    0.005272\n",
      "16.93    0.003515\n",
      "30.50    0.003515\n",
      "23.17    0.003515\n",
      "           ...   \n",
      "32.06    0.001757\n",
      "24.70    0.001757\n",
      "22.00    0.001757\n",
      "39.34    0.001757\n",
      "30.37    0.001757\n",
      "Name: worst texture, Length: 511, dtype: float64, 117.70    0.005272\n",
      "105.90    0.005272\n",
      "101.70    0.005272\n",
      "184.60    0.003515\n",
      "106.40    0.003515\n",
      "            ...   \n",
      "79.57     0.001757\n",
      "84.42     0.001757\n",
      "139.20    0.001757\n",
      "75.39     0.001757\n",
      "59.16     0.001757\n",
      "Name: worst perimeter, Length: 514, dtype: float64, 472.4     0.003515\n",
      "1210.0    0.003515\n",
      "826.4     0.003515\n",
      "402.8     0.003515\n",
      "1750.0    0.003515\n",
      "            ...   \n",
      "579.5     0.001757\n",
      "762.4     0.001757\n",
      "521.5     0.001757\n",
      "1410.0    0.001757\n",
      "268.6     0.001757\n",
      "Name: worst area, Length: 544, dtype: float64, 0.13470    0.007030\n",
      "0.12750    0.007030\n",
      "0.12230    0.007030\n",
      "0.14010    0.007030\n",
      "0.12340    0.007030\n",
      "             ...   \n",
      "0.22260    0.001757\n",
      "0.13810    0.001757\n",
      "0.14290    0.001757\n",
      "0.13220    0.001757\n",
      "0.08996    0.001757\n",
      "Name: worst smoothness, Length: 411, dtype: float64, 0.34160    0.005272\n",
      "0.14860    0.005272\n",
      "0.21700    0.003515\n",
      "0.09866    0.003515\n",
      "0.22640    0.003515\n",
      "             ...   \n",
      "0.24450    0.001757\n",
      "0.10190    0.001757\n",
      "0.32990    0.001757\n",
      "0.16100    0.001757\n",
      "0.06444    0.001757\n",
      "Name: worst compactness, Length: 529, dtype: float64, 0.00000    0.022847\n",
      "0.45040    0.005272\n",
      "0.13770    0.005272\n",
      "0.18040    0.003515\n",
      "0.18110    0.003515\n",
      "             ...   \n",
      "0.00692    0.001757\n",
      "0.16480    0.001757\n",
      "0.29020    0.001757\n",
      "0.67800    0.001757\n",
      "0.93870    0.001757\n",
      "Name: worst concavity, Length: 539, dtype: float64, 0.00000    0.022847\n",
      "0.05556    0.005272\n",
      "0.06296    0.005272\n",
      "0.12180    0.005272\n",
      "0.07431    0.005272\n",
      "             ...   \n",
      "0.15410    0.001757\n",
      "0.29030    0.001757\n",
      "0.26880    0.001757\n",
      "0.03990    0.001757\n",
      "0.26500    0.001757\n",
      "Name: worst concave points, Length: 492, dtype: float64, 0.2226    0.005272\n",
      "0.2369    0.005272\n",
      "0.2972    0.005272\n",
      "0.3196    0.005272\n",
      "0.3109    0.005272\n",
      "            ...   \n",
      "0.3024    0.001757\n",
      "0.3000    0.001757\n",
      "0.3215    0.001757\n",
      "0.1909    0.001757\n",
      "0.4087    0.001757\n",
      "Name: worst symmetry, Length: 500, dtype: float64, 0.07427    0.005272\n",
      "0.09026    0.003515\n",
      "0.12970    0.003515\n",
      "0.08174    0.003515\n",
      "0.10550    0.003515\n",
      "             ...   \n",
      "0.06938    0.001757\n",
      "0.07697    0.001757\n",
      "0.09772    0.001757\n",
      "0.08631    0.001757\n",
      "0.07039    0.001757\n",
      "Name: worst fractal dimension, Length: 535, dtype: float64, 1    0.627417\n",
      "0    0.372583\n",
      "Name: target, dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "print([df[c].value_counts() for c in df])\n",
    "print([df[c].value_counts(normalize=True) for c in df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ff900",
   "metadata": {},
   "source": [
    "### 결측치 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d91d9c8",
   "metadata": {},
   "source": [
    "</br> 3-1 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5a3a75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0\n",
       "mean texture               0\n",
       "mean perimeter             0\n",
       "mean area                  0\n",
       "mean smoothness            0\n",
       "mean compactness           0\n",
       "mean concavity             0\n",
       "mean concave points        0\n",
       "mean symmetry              0\n",
       "mean fractal dimension     0\n",
       "radius error               0\n",
       "texture error              0\n",
       "perimeter error            0\n",
       "area error                 0\n",
       "smoothness error           0\n",
       "compactness error          0\n",
       "concavity error            0\n",
       "concave points error       0\n",
       "symmetry error             0\n",
       "fractal dimension error    0\n",
       "worst radius               0\n",
       "worst texture              0\n",
       "worst perimeter            0\n",
       "worst area                 0\n",
       "worst smoothness           0\n",
       "worst compactness          0\n",
       "worst concavity            0\n",
       "worst concave points       0\n",
       "worst symmetry             0\n",
       "worst fractal dimension    0\n",
       "target                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa58eef",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "2-2 결측치 채우기\n",
    "- 수치형인 경우 median 값과, mean, 선형 보간법, bfill, ffill 등으로 채움\n",
    "- 명목형인 경우 mode 값으로 채움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "703dd64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 명목형 데이터\n",
    "# mode = df['target'].value_counts()[0]\n",
    "# df['taget'].fillna(mode, inplace=True)\n",
    "\n",
    "## 수치형 데이터\n",
    "# mean = df['mean radius'].mean() # median()\n",
    "# df['mean radius'].fillna(mean, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab9339d",
   "metadata": {},
   "source": [
    "</br>\n",
    "2-3 이상한 값이 포함된 경우 결측치로 바꾸기\n",
    "</br>\n",
    "ex) 수치형 컬럼에 문자 데이터가 포함된 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0358dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['mean radius'].replace(np.nan, \"s\", inplace = True)\n",
    "# df.loc[df['mean radius'] == 's', mean radius'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a5995",
   "metadata": {},
   "source": [
    "### 필요할 컬럼만 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afd5567",
   "metadata": {},
   "source": [
    "</br>\n",
    "3-1 데이터프레임 컬럼 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1690057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
       "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
       "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
       "       'worst concave points', 'worst symmetry', 'worst fractal dimension',\n",
       "       'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc198ba",
   "metadata": {},
   "source": [
    "</br>\n",
    "3-2 불필요한 컬럼 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8cc75c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['radius error', 'texture error', 'perimeter error', 'area error',\n",
    "       'smoothness error', 'compactness error', 'concavity error',\n",
    "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
    "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
    "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
    "       'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
    "df.drop(drop_cols, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb809aad",
   "metadata": {},
   "source": [
    "### target 라벨인코딩, 원핫 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755c583b",
   "metadata": {},
   "source": [
    "</br>\n",
    "4-1 target 데이터가 문자형인 경우 수치형 데이터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8727fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(data['target'])\n",
    "data['target'] = encoder.transform(data['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb63200",
   "metadata": {},
   "source": [
    "</br>\n",
    "4-2 object 컬럼에 대해서 one-hot-encoding 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "356ea5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dum_cols = ['a', 'b']\n",
    "# pd.get_dummies(data = df, columns=dum_cols, drop_first=True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ff8ae8",
   "metadata": {},
   "source": [
    "### x, y 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8bee9a",
   "metadata": {},
   "source": [
    "</br> 5-1 x와 y 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d02188f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('target', axis = 1)\n",
    "y = df.loc[:,'target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193630e9",
   "metadata": {},
   "source": [
    "</br> \n",
    "5-2 train_test_split 8:2  비율로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42141189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=.2, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9dd8be",
   "metadata": {},
   "source": [
    "### 데이터 정규분포, 표준화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba4a71",
   "metadata": {},
   "source": [
    "</br>\n",
    "6-1 standardscaler를 사용하여 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79a74ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3add53",
   "metadata": {},
   "source": [
    "### 머신러닝 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf9a617",
   "metadata": {},
   "source": [
    "7-1 Logistic Regression 모델 학습 (규제 강도 C는 10, max_iter = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ddb0611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression(C = 10, max_iter=2000)\n",
    "lr_model.fit(x_train, y_train)\n",
    "lr_pred = lr_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b2f2d1",
   "metadata": {},
   "source": [
    "7-2 classification_report로 성능출력하고, confusion matrix를 구하여 heatmap으로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a9cc5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 300x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "plt.figure(figsize= (3, 3))\n",
    "sns.heatmap(confusion_matrix(y_test, lr_pred),\n",
    "           cmap = 'Blues',\n",
    "           annot = True,\n",
    "           annot_kws = {'size' : 15},\n",
    "           square = True,\n",
    "           fmt = '.1f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f527e3bb",
   "metadata": {},
   "source": [
    "### 딥러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba842446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77de7f9e",
   "metadata": {},
   "source": [
    "</br>\n",
    "8-1 input shape 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4de7ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 10), (455,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72639152",
   "metadata": {},
   "source": [
    "8-2 이진분류 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e9ff741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                704       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 769\n",
      "Trainable params: 769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1. 세션 클리어\n",
    "clear_session()\n",
    "\n",
    "# 2. model 선언\n",
    "model = Sequential()\n",
    "\n",
    "# 3. model 블록 조립\n",
    "model.add(Dense(units = 64, activation = 'swish', input_shape = (10,)))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "# 4. model compile\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "             metrics = ['acc'],\n",
    "             optimizer = 'adam')\n",
    "\n",
    "# 5. model summary()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4f8d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "mc = ModelCheckpoint(filepath = 'model.h5', \n",
    "                     monitor='val_loss',\n",
    "                     save_best_only=True, \n",
    "                     save_weights_only=False)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss',\n",
    "                  min_delta = 0,\n",
    "                  patience = 5,\n",
    "                  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67d88b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8866 - acc: 0.1181 - val_loss: 0.8788 - val_acc: 0.1319\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.8635 - acc: 0.1236 - val_loss: 0.8552 - val_acc: 0.1429\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.8408 - acc: 0.1484 - val_loss: 0.8322 - val_acc: 0.1758\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.8187 - acc: 0.1868 - val_loss: 0.8097 - val_acc: 0.1868\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7971 - acc: 0.2473 - val_loss: 0.7877 - val_acc: 0.2637\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7760 - acc: 0.3104 - val_loss: 0.7663 - val_acc: 0.3297\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7555 - acc: 0.3791 - val_loss: 0.7455 - val_acc: 0.4176\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7355 - acc: 0.4258 - val_loss: 0.7253 - val_acc: 0.5055\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7161 - acc: 0.5055 - val_loss: 0.7057 - val_acc: 0.5275\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6972 - acc: 0.5797 - val_loss: 0.6867 - val_acc: 0.5714\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6790 - acc: 0.6401 - val_loss: 0.6684 - val_acc: 0.6154\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6613 - acc: 0.6841 - val_loss: 0.6506 - val_acc: 0.6923\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6442 - acc: 0.7335 - val_loss: 0.6335 - val_acc: 0.7363\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6277 - acc: 0.7555 - val_loss: 0.6171 - val_acc: 0.8022\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6117 - acc: 0.7830 - val_loss: 0.6012 - val_acc: 0.8352\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5964 - acc: 0.8077 - val_loss: 0.5860 - val_acc: 0.8352\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5816 - acc: 0.8214 - val_loss: 0.5714 - val_acc: 0.8791\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5674 - acc: 0.8352 - val_loss: 0.5573 - val_acc: 0.8791\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5538 - acc: 0.8489 - val_loss: 0.5439 - val_acc: 0.8901\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5406 - acc: 0.8681 - val_loss: 0.5309 - val_acc: 0.8901\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5280 - acc: 0.8764 - val_loss: 0.5185 - val_acc: 0.8901\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5159 - acc: 0.8819 - val_loss: 0.5067 - val_acc: 0.9121\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5043 - acc: 0.8901 - val_loss: 0.4953 - val_acc: 0.9121\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4931 - acc: 0.8956 - val_loss: 0.4844 - val_acc: 0.9121\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4824 - acc: 0.8984 - val_loss: 0.4739 - val_acc: 0.9231\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4721 - acc: 0.9038 - val_loss: 0.4639 - val_acc: 0.9231\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4622 - acc: 0.9066 - val_loss: 0.4543 - val_acc: 0.9231\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4528 - acc: 0.9176 - val_loss: 0.4451 - val_acc: 0.9341\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4437 - acc: 0.9176 - val_loss: 0.4363 - val_acc: 0.9341\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4349 - acc: 0.9176 - val_loss: 0.4278 - val_acc: 0.9451\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4265 - acc: 0.9176 - val_loss: 0.4197 - val_acc: 0.9451\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4184 - acc: 0.9203 - val_loss: 0.4118 - val_acc: 0.9451\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4107 - acc: 0.9203 - val_loss: 0.4044 - val_acc: 0.9451\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4032 - acc: 0.9231 - val_loss: 0.3972 - val_acc: 0.9451\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3960 - acc: 0.9231 - val_loss: 0.3902 - val_acc: 0.9341\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3891 - acc: 0.9231 - val_loss: 0.3836 - val_acc: 0.9341\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3825 - acc: 0.9286 - val_loss: 0.3772 - val_acc: 0.9341\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3761 - acc: 0.9313 - val_loss: 0.3710 - val_acc: 0.9341\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3699 - acc: 0.9313 - val_loss: 0.3651 - val_acc: 0.9341\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3639 - acc: 0.9313 - val_loss: 0.3594 - val_acc: 0.9341\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3582 - acc: 0.9313 - val_loss: 0.3539 - val_acc: 0.9341\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.3526 - acc: 0.9313 - val_loss: 0.3487 - val_acc: 0.9341\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.3473 - acc: 0.9313 - val_loss: 0.3436 - val_acc: 0.9341\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.3421 - acc: 0.9286 - val_loss: 0.3387 - val_acc: 0.9341\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3371 - acc: 0.9286 - val_loss: 0.3339 - val_acc: 0.9341\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.3323 - acc: 0.9286 - val_loss: 0.3293 - val_acc: 0.9341\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.3277 - acc: 0.9258 - val_loss: 0.3249 - val_acc: 0.9231\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3231 - acc: 0.9258 - val_loss: 0.3207 - val_acc: 0.9231\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3188 - acc: 0.9286 - val_loss: 0.3166 - val_acc: 0.9231\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3146 - acc: 0.9286 - val_loss: 0.3126 - val_acc: 0.9231\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3105 - acc: 0.9313 - val_loss: 0.3087 - val_acc: 0.9231\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3065 - acc: 0.9313 - val_loss: 0.3050 - val_acc: 0.9231\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3027 - acc: 0.9313 - val_loss: 0.3014 - val_acc: 0.9231\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2989 - acc: 0.9313 - val_loss: 0.2980 - val_acc: 0.9231\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.2953 - acc: 0.9313 - val_loss: 0.2946 - val_acc: 0.9231\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2918 - acc: 0.9313 - val_loss: 0.2913 - val_acc: 0.9231\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2884 - acc: 0.9313 - val_loss: 0.2882 - val_acc: 0.9231\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2851 - acc: 0.9341 - val_loss: 0.2851 - val_acc: 0.9231\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.2819 - acc: 0.9341 - val_loss: 0.2822 - val_acc: 0.9231\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.2788 - acc: 0.9341 - val_loss: 0.2793 - val_acc: 0.9231\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.2757 - acc: 0.9368 - val_loss: 0.2765 - val_acc: 0.9231\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2728 - acc: 0.9341 - val_loss: 0.2738 - val_acc: 0.9231\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2699 - acc: 0.9341 - val_loss: 0.2712 - val_acc: 0.9231\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.2672 - acc: 0.9341 - val_loss: 0.2687 - val_acc: 0.9231\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.2644 - acc: 0.9341 - val_loss: 0.2662 - val_acc: 0.9231\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.2618 - acc: 0.9341 - val_loss: 0.2638 - val_acc: 0.9231\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2592 - acc: 0.9341 - val_loss: 0.2615 - val_acc: 0.9231\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2567 - acc: 0.9341 - val_loss: 0.2592 - val_acc: 0.9231\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2543 - acc: 0.9341 - val_loss: 0.2570 - val_acc: 0.9231\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2519 - acc: 0.9341 - val_loss: 0.2549 - val_acc: 0.9231\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2496 - acc: 0.9341 - val_loss: 0.2528 - val_acc: 0.9231\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2473 - acc: 0.9341 - val_loss: 0.2508 - val_acc: 0.9231\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2451 - acc: 0.9341 - val_loss: 0.2488 - val_acc: 0.9231\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2430 - acc: 0.9313 - val_loss: 0.2469 - val_acc: 0.9231\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2409 - acc: 0.9313 - val_loss: 0.2451 - val_acc: 0.9231\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2388 - acc: 0.9313 - val_loss: 0.2433 - val_acc: 0.9231\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2368 - acc: 0.9313 - val_loss: 0.2415 - val_acc: 0.9231\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2349 - acc: 0.9313 - val_loss: 0.2398 - val_acc: 0.9231\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2330 - acc: 0.9313 - val_loss: 0.2381 - val_acc: 0.9231\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2311 - acc: 0.9313 - val_loss: 0.2365 - val_acc: 0.9231\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2293 - acc: 0.9341 - val_loss: 0.2349 - val_acc: 0.9231\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2275 - acc: 0.9341 - val_loss: 0.2333 - val_acc: 0.9231\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2257 - acc: 0.9313 - val_loss: 0.2318 - val_acc: 0.9231\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2240 - acc: 0.9313 - val_loss: 0.2304 - val_acc: 0.9231\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2224 - acc: 0.9313 - val_loss: 0.2289 - val_acc: 0.9231\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2207 - acc: 0.9313 - val_loss: 0.2275 - val_acc: 0.9231\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2191 - acc: 0.9313 - val_loss: 0.2262 - val_acc: 0.9231\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2176 - acc: 0.9313 - val_loss: 0.2248 - val_acc: 0.9231\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2161 - acc: 0.9313 - val_loss: 0.2236 - val_acc: 0.9231\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2146 - acc: 0.9313 - val_loss: 0.2223 - val_acc: 0.9231\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2131 - acc: 0.9313 - val_loss: 0.2210 - val_acc: 0.9231\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2117 - acc: 0.9313 - val_loss: 0.2198 - val_acc: 0.9231\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2102 - acc: 0.9313 - val_loss: 0.2187 - val_acc: 0.9231\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2089 - acc: 0.9313 - val_loss: 0.2175 - val_acc: 0.9231\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2075 - acc: 0.9341 - val_loss: 0.2164 - val_acc: 0.9231\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2062 - acc: 0.9341 - val_loss: 0.2153 - val_acc: 0.9231\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2049 - acc: 0.9341 - val_loss: 0.2142 - val_acc: 0.9231\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2036 - acc: 0.9341 - val_loss: 0.2132 - val_acc: 0.9231\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2024 - acc: 0.9341 - val_loss: 0.2121 - val_acc: 0.9231\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2011 - acc: 0.9341 - val_loss: 0.2111 - val_acc: 0.9231\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1999 - acc: 0.9341 - val_loss: 0.2101 - val_acc: 0.9231\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1987 - acc: 0.9341 - val_loss: 0.2092 - val_acc: 0.9231\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1976 - acc: 0.9341 - val_loss: 0.2082 - val_acc: 0.9231\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1964 - acc: 0.9341 - val_loss: 0.2073 - val_acc: 0.9231\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1953 - acc: 0.9341 - val_loss: 0.2064 - val_acc: 0.9231\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1942 - acc: 0.9341 - val_loss: 0.2056 - val_acc: 0.9231\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1932 - acc: 0.9341 - val_loss: 0.2047 - val_acc: 0.9231\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1921 - acc: 0.9341 - val_loss: 0.2039 - val_acc: 0.9231\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1911 - acc: 0.9341 - val_loss: 0.2030 - val_acc: 0.9231\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1900 - acc: 0.9341 - val_loss: 0.2022 - val_acc: 0.9231\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1890 - acc: 0.9341 - val_loss: 0.2014 - val_acc: 0.9231\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1880 - acc: 0.9341 - val_loss: 0.2007 - val_acc: 0.9231\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1871 - acc: 0.9341 - val_loss: 0.1999 - val_acc: 0.9231\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1861 - acc: 0.9341 - val_loss: 0.1992 - val_acc: 0.9231\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1852 - acc: 0.9341 - val_loss: 0.1985 - val_acc: 0.9231\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1843 - acc: 0.9341 - val_loss: 0.1977 - val_acc: 0.9231\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1834 - acc: 0.9341 - val_loss: 0.1970 - val_acc: 0.9231\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1825 - acc: 0.9341 - val_loss: 0.1964 - val_acc: 0.9231\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1816 - acc: 0.9341 - val_loss: 0.1957 - val_acc: 0.9231\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1807 - acc: 0.9341 - val_loss: 0.1950 - val_acc: 0.9231\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1799 - acc: 0.9341 - val_loss: 0.1944 - val_acc: 0.9231\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1790 - acc: 0.9341 - val_loss: 0.1938 - val_acc: 0.9231\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1782 - acc: 0.9341 - val_loss: 0.1932 - val_acc: 0.9231\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1774 - acc: 0.9341 - val_loss: 0.1926 - val_acc: 0.9231\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1766 - acc: 0.9341 - val_loss: 0.1920 - val_acc: 0.9231\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1758 - acc: 0.9341 - val_loss: 0.1914 - val_acc: 0.9231\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1751 - acc: 0.9341 - val_loss: 0.1908 - val_acc: 0.9231\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1743 - acc: 0.9341 - val_loss: 0.1903 - val_acc: 0.9231\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1736 - acc: 0.9341 - val_loss: 0.1897 - val_acc: 0.9231\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1728 - acc: 0.9341 - val_loss: 0.1892 - val_acc: 0.9231\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1721 - acc: 0.9341 - val_loss: 0.1887 - val_acc: 0.9231\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1714 - acc: 0.9341 - val_loss: 0.1882 - val_acc: 0.9231\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1707 - acc: 0.9341 - val_loss: 0.1877 - val_acc: 0.9231\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1700 - acc: 0.9341 - val_loss: 0.1872 - val_acc: 0.9231\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1693 - acc: 0.9341 - val_loss: 0.1867 - val_acc: 0.9231\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1687 - acc: 0.9341 - val_loss: 0.1862 - val_acc: 0.9231\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1680 - acc: 0.9341 - val_loss: 0.1857 - val_acc: 0.9231\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1673 - acc: 0.9341 - val_loss: 0.1853 - val_acc: 0.9231\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1667 - acc: 0.9341 - val_loss: 0.1848 - val_acc: 0.9231\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1661 - acc: 0.9341 - val_loss: 0.1844 - val_acc: 0.9231\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1654 - acc: 0.9341 - val_loss: 0.1840 - val_acc: 0.9231\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.1648 - acc: 0.9341 - val_loss: 0.1835 - val_acc: 0.9231\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1642 - acc: 0.9341 - val_loss: 0.1831 - val_acc: 0.9231\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.1636 - acc: 0.9341 - val_loss: 0.1827 - val_acc: 0.9231\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1630 - acc: 0.9341 - val_loss: 0.1823 - val_acc: 0.9231\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1625 - acc: 0.9341 - val_loss: 0.1819 - val_acc: 0.9231\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1619 - acc: 0.9341 - val_loss: 0.1816 - val_acc: 0.9231\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1613 - acc: 0.9341 - val_loss: 0.1812 - val_acc: 0.9231\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1608 - acc: 0.9341 - val_loss: 0.1808 - val_acc: 0.9231\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1602 - acc: 0.9341 - val_loss: 0.1804 - val_acc: 0.9231\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1597 - acc: 0.9341 - val_loss: 0.1801 - val_acc: 0.9231\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1591 - acc: 0.9341 - val_loss: 0.1797 - val_acc: 0.9231\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1586 - acc: 0.9341 - val_loss: 0.1794 - val_acc: 0.9231\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1581 - acc: 0.9368 - val_loss: 0.1791 - val_acc: 0.9231\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1576 - acc: 0.9396 - val_loss: 0.1787 - val_acc: 0.9231\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1571 - acc: 0.9396 - val_loss: 0.1784 - val_acc: 0.9231\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1566 - acc: 0.9396 - val_loss: 0.1781 - val_acc: 0.9231\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1561 - acc: 0.9423 - val_loss: 0.1778 - val_acc: 0.9231\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1556 - acc: 0.9423 - val_loss: 0.1775 - val_acc: 0.9231\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1551 - acc: 0.9423 - val_loss: 0.1772 - val_acc: 0.9231\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1546 - acc: 0.9423 - val_loss: 0.1769 - val_acc: 0.9231\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1542 - acc: 0.9423 - val_loss: 0.1766 - val_acc: 0.9231\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.1537 - acc: 0.9423 - val_loss: 0.1763 - val_acc: 0.9231\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.1533 - acc: 0.9423 - val_loss: 0.1760 - val_acc: 0.9231\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.1528 - acc: 0.9423 - val_loss: 0.1757 - val_acc: 0.9231\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1524 - acc: 0.9423 - val_loss: 0.1755 - val_acc: 0.9231\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.1519 - acc: 0.9423 - val_loss: 0.1752 - val_acc: 0.9231\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.1515 - acc: 0.9423 - val_loss: 0.1749 - val_acc: 0.9231\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.1511 - acc: 0.9423 - val_loss: 0.1747 - val_acc: 0.9231\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.1506 - acc: 0.9423 - val_loss: 0.1744 - val_acc: 0.9231\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1502 - acc: 0.9423 - val_loss: 0.1742 - val_acc: 0.9231\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1498 - acc: 0.9423 - val_loss: 0.1740 - val_acc: 0.9231\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.1494 - acc: 0.9423 - val_loss: 0.1737 - val_acc: 0.9231\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1490 - acc: 0.9423 - val_loss: 0.1735 - val_acc: 0.9231\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1486 - acc: 0.9423 - val_loss: 0.1733 - val_acc: 0.9231\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.1482 - acc: 0.9423 - val_loss: 0.1730 - val_acc: 0.9231\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1478 - acc: 0.9423 - val_loss: 0.1728 - val_acc: 0.9231\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.1475 - acc: 0.9423 - val_loss: 0.1726 - val_acc: 0.9231\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.1471 - acc: 0.9423 - val_loss: 0.1724 - val_acc: 0.9231\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.1467 - acc: 0.9423 - val_loss: 0.1722 - val_acc: 0.9231\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.1463 - acc: 0.9423 - val_loss: 0.1720 - val_acc: 0.9121\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.1460 - acc: 0.9423 - val_loss: 0.1718 - val_acc: 0.9121\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.1456 - acc: 0.9423 - val_loss: 0.1716 - val_acc: 0.9121\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1453 - acc: 0.9423 - val_loss: 0.1714 - val_acc: 0.9121\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1449 - acc: 0.9423 - val_loss: 0.1712 - val_acc: 0.9121\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1446 - acc: 0.9423 - val_loss: 0.1710 - val_acc: 0.9121\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1442 - acc: 0.9423 - val_loss: 0.1708 - val_acc: 0.9121\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1439 - acc: 0.9423 - val_loss: 0.1707 - val_acc: 0.9121\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1435 - acc: 0.9423 - val_loss: 0.1705 - val_acc: 0.9121\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1432 - acc: 0.9423 - val_loss: 0.1703 - val_acc: 0.9121\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1429 - acc: 0.9423 - val_loss: 0.1701 - val_acc: 0.9121\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1426 - acc: 0.9423 - val_loss: 0.1700 - val_acc: 0.9121\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1422 - acc: 0.9423 - val_loss: 0.1698 - val_acc: 0.9121\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1419 - acc: 0.9423 - val_loss: 0.1697 - val_acc: 0.9121\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1416 - acc: 0.9423 - val_loss: 0.1695 - val_acc: 0.9121\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1413 - acc: 0.9423 - val_loss: 0.1693 - val_acc: 0.9121\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1410 - acc: 0.9423 - val_loss: 0.1692 - val_acc: 0.9121\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1407 - acc: 0.9423 - val_loss: 0.1690 - val_acc: 0.9121\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1404 - acc: 0.9423 - val_loss: 0.1689 - val_acc: 0.9121\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1401 - acc: 0.9423 - val_loss: 0.1688 - val_acc: 0.9121\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1398 - acc: 0.9423 - val_loss: 0.1686 - val_acc: 0.9121\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1395 - acc: 0.9423 - val_loss: 0.1685 - val_acc: 0.9121\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1392 - acc: 0.9451 - val_loss: 0.1683 - val_acc: 0.9121\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1390 - acc: 0.9451 - val_loss: 0.1682 - val_acc: 0.9121\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1387 - acc: 0.9451 - val_loss: 0.1681 - val_acc: 0.9121\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1384 - acc: 0.9451 - val_loss: 0.1680 - val_acc: 0.9121\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1381 - acc: 0.9451 - val_loss: 0.1678 - val_acc: 0.9121\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1379 - acc: 0.9451 - val_loss: 0.1677 - val_acc: 0.9121\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1376 - acc: 0.9451 - val_loss: 0.1676 - val_acc: 0.9121\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1373 - acc: 0.9451 - val_loss: 0.1675 - val_acc: 0.9121\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1371 - acc: 0.9451 - val_loss: 0.1674 - val_acc: 0.9121\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1368 - acc: 0.9451 - val_loss: 0.1672 - val_acc: 0.9121\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.1366 - acc: 0.9451 - val_loss: 0.1671 - val_acc: 0.9121\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1363 - acc: 0.9451 - val_loss: 0.1670 - val_acc: 0.9121\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1361 - acc: 0.9478 - val_loss: 0.1669 - val_acc: 0.9121\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1358 - acc: 0.9478 - val_loss: 0.1668 - val_acc: 0.9121\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1356 - acc: 0.9478 - val_loss: 0.1667 - val_acc: 0.9121\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1353 - acc: 0.9478 - val_loss: 0.1666 - val_acc: 0.9121\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1351 - acc: 0.9478 - val_loss: 0.1665 - val_acc: 0.9121\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1348 - acc: 0.9478 - val_loss: 0.1664 - val_acc: 0.9121\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1346 - acc: 0.9478 - val_loss: 0.1663 - val_acc: 0.9121\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1344 - acc: 0.9478 - val_loss: 0.1662 - val_acc: 0.9121\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1342 - acc: 0.9478 - val_loss: 0.1661 - val_acc: 0.9121\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1339 - acc: 0.9478 - val_loss: 0.1661 - val_acc: 0.9121\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1337 - acc: 0.9478 - val_loss: 0.1660 - val_acc: 0.9121\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1335 - acc: 0.9478 - val_loss: 0.1659 - val_acc: 0.9121\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1333 - acc: 0.9478 - val_loss: 0.1658 - val_acc: 0.9121\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1330 - acc: 0.9478 - val_loss: 0.1657 - val_acc: 0.9121\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1328 - acc: 0.9478 - val_loss: 0.1656 - val_acc: 0.9121\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1326 - acc: 0.9505 - val_loss: 0.1656 - val_acc: 0.9121\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1324 - acc: 0.9505 - val_loss: 0.1655 - val_acc: 0.9121\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1322 - acc: 0.9505 - val_loss: 0.1654 - val_acc: 0.9121\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1320 - acc: 0.9505 - val_loss: 0.1653 - val_acc: 0.9121\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1318 - acc: 0.9505 - val_loss: 0.1653 - val_acc: 0.9121\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.1316 - acc: 0.9505 - val_loss: 0.1652 - val_acc: 0.9121\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1314 - acc: 0.9505 - val_loss: 0.1651 - val_acc: 0.9121\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1312 - acc: 0.9505 - val_loss: 0.1651 - val_acc: 0.9121\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.1310 - acc: 0.9505 - val_loss: 0.1650 - val_acc: 0.9121\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1308 - acc: 0.9505 - val_loss: 0.1649 - val_acc: 0.9121\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1306 - acc: 0.9505 - val_loss: 0.1649 - val_acc: 0.9121\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1304 - acc: 0.9505 - val_loss: 0.1648 - val_acc: 0.9121\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1302 - acc: 0.9505 - val_loss: 0.1647 - val_acc: 0.9121\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.1300 - acc: 0.9505 - val_loss: 0.1647 - val_acc: 0.9121\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1298 - acc: 0.9505 - val_loss: 0.1646 - val_acc: 0.9121\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.1296 - acc: 0.9533 - val_loss: 0.1646 - val_acc: 0.9121\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1295 - acc: 0.9533 - val_loss: 0.1645 - val_acc: 0.9121\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.1293 - acc: 0.9533 - val_loss: 0.1645 - val_acc: 0.9121\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1291 - acc: 0.9533 - val_loss: 0.1644 - val_acc: 0.9121\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1289 - acc: 0.9533 - val_loss: 0.1644 - val_acc: 0.9121\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1287 - acc: 0.9533 - val_loss: 0.1643 - val_acc: 0.9121\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1286 - acc: 0.9533 - val_loss: 0.1643 - val_acc: 0.9121\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1284 - acc: 0.9533 - val_loss: 0.1642 - val_acc: 0.9121\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1282 - acc: 0.9533 - val_loss: 0.1642 - val_acc: 0.9121\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1281 - acc: 0.9533 - val_loss: 0.1641 - val_acc: 0.9121\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1279 - acc: 0.9533 - val_loss: 0.1641 - val_acc: 0.9121\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1277 - acc: 0.9533 - val_loss: 0.1640 - val_acc: 0.9121\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1276 - acc: 0.9533 - val_loss: 0.1640 - val_acc: 0.9121\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1274 - acc: 0.9533 - val_loss: 0.1640 - val_acc: 0.9121\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1272 - acc: 0.9533 - val_loss: 0.1639 - val_acc: 0.9121\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1271 - acc: 0.9533 - val_loss: 0.1639 - val_acc: 0.9121\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1269 - acc: 0.9533 - val_loss: 0.1638 - val_acc: 0.9121\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.1268 - acc: 0.9533 - val_loss: 0.1638 - val_acc: 0.9121\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.1266 - acc: 0.9533 - val_loss: 0.1638 - val_acc: 0.9121\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.1265 - acc: 0.9533 - val_loss: 0.1637 - val_acc: 0.9121\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.1263 - acc: 0.9533 - val_loss: 0.1637 - val_acc: 0.9121\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1261 - acc: 0.9533 - val_loss: 0.1637 - val_acc: 0.9121\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1260 - acc: 0.9533 - val_loss: 0.1636 - val_acc: 0.9121\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1259 - acc: 0.9533 - val_loss: 0.1636 - val_acc: 0.9121\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1257 - acc: 0.9533 - val_loss: 0.1636 - val_acc: 0.9121\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.1256 - acc: 0.9533 - val_loss: 0.1635 - val_acc: 0.9121\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1254 - acc: 0.9533 - val_loss: 0.1635 - val_acc: 0.9121\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1253 - acc: 0.9533 - val_loss: 0.1635 - val_acc: 0.9121\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1251 - acc: 0.9533 - val_loss: 0.1635 - val_acc: 0.9121\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1250 - acc: 0.9533 - val_loss: 0.1634 - val_acc: 0.9121\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1248 - acc: 0.9533 - val_loss: 0.1634 - val_acc: 0.9121\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1247 - acc: 0.9533 - val_loss: 0.1634 - val_acc: 0.9121\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1246 - acc: 0.9533 - val_loss: 0.1634 - val_acc: 0.9121\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1244 - acc: 0.9533 - val_loss: 0.1633 - val_acc: 0.9121\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.1243 - acc: 0.9533 - val_loss: 0.1633 - val_acc: 0.9121\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1242 - acc: 0.9533 - val_loss: 0.1633 - val_acc: 0.9121\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.1240 - acc: 0.9533 - val_loss: 0.1633 - val_acc: 0.9121\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.1239 - acc: 0.9533 - val_loss: 0.1632 - val_acc: 0.9121\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1238 - acc: 0.9533 - val_loss: 0.1632 - val_acc: 0.9121\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1236 - acc: 0.9533 - val_loss: 0.1632 - val_acc: 0.9121\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1235 - acc: 0.9533 - val_loss: 0.1632 - val_acc: 0.9121\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1234 - acc: 0.9533 - val_loss: 0.1632 - val_acc: 0.9121\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.1233 - acc: 0.9533 - val_loss: 0.1632 - val_acc: 0.9121\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1231 - acc: 0.9533 - val_loss: 0.1631 - val_acc: 0.9121\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1230 - acc: 0.9533 - val_loss: 0.1631 - val_acc: 0.9121\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1229 - acc: 0.9533 - val_loss: 0.1631 - val_acc: 0.9121\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1228 - acc: 0.9533 - val_loss: 0.1631 - val_acc: 0.9121\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1226 - acc: 0.9533 - val_loss: 0.1631 - val_acc: 0.9121\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1225 - acc: 0.9533 - val_loss: 0.1631 - val_acc: 0.9121\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1224 - acc: 0.9533 - val_loss: 0.1631 - val_acc: 0.9121\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1223 - acc: 0.9533 - val_loss: 0.1630 - val_acc: 0.9121\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1222 - acc: 0.9533 - val_loss: 0.1630 - val_acc: 0.9121\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1220 - acc: 0.9533 - val_loss: 0.1630 - val_acc: 0.9121\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1219 - acc: 0.9533 - val_loss: 0.1630 - val_acc: 0.9121\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1218 - acc: 0.9533 - val_loss: 0.1630 - val_acc: 0.9121\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1217 - acc: 0.9533 - val_loss: 0.1630 - val_acc: 0.9121\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1216 - acc: 0.9533 - val_loss: 0.1630 - val_acc: 0.9121\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.1215 - acc: 0.9533 - val_loss: 0.1630 - val_acc: 0.9121\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.1214 - acc: 0.9533 - val_loss: 0.1630 - val_acc: 0.9121\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1213 - acc: 0.9505 - val_loss: 0.1630 - val_acc: 0.9121\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1211 - acc: 0.9505 - val_loss: 0.1630 - val_acc: 0.9121\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1210 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.1209 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1208 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.1207 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.1206 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1205 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.1204 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.1203 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1202 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1201 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1200 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.1199 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.1198 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.1197 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.1196 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.1195 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1194 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1193 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1192 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1191 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1190 - acc: 0.9505 - val_loss: 0.1629 - val_acc: 0.9121\n",
      "Epoch 326: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19192894790>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "         callbacks=[es, mc], batch_size=2048, epochs=1000,\n",
    "         validation_split=.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4bf09f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1732d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1659 - acc: 0.9649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16586676239967346, 0.9649122953414917]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e87c4",
   "metadata": {},
   "source": [
    "8-3 다중분류 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b6ace9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y categorical 진행\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, len(set(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5aa1ba4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                704       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 834\n",
      "Trainable params: 834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1. 세션 클리어\n",
    "clear_session()\n",
    "\n",
    "# 2. model 선언\n",
    "model = Sequential()\n",
    "\n",
    "# 3. model 블록 조립\n",
    "model.add(Dense(units = 64, activation = 'swish', input_shape = (10,)))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "# 4. model compile\n",
    "model.compile(loss = keras.losses.categorical_crossentropy,\n",
    "             metrics = ['acc'],\n",
    "             optimizer = 'adam')\n",
    "\n",
    "# 5. model summary()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2689b112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6832 - acc: 0.6016 - val_loss: 0.6876 - val_acc: 0.6154\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6617 - acc: 0.6346 - val_loss: 0.6665 - val_acc: 0.6154\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6410 - acc: 0.6621 - val_loss: 0.6462 - val_acc: 0.6484\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6211 - acc: 0.6868 - val_loss: 0.6266 - val_acc: 0.6703\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6021 - acc: 0.7033 - val_loss: 0.6078 - val_acc: 0.6813\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5838 - acc: 0.7225 - val_loss: 0.5897 - val_acc: 0.7033\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5663 - acc: 0.7500 - val_loss: 0.5723 - val_acc: 0.7253\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5495 - acc: 0.7720 - val_loss: 0.5556 - val_acc: 0.7582\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5333 - acc: 0.7857 - val_loss: 0.5395 - val_acc: 0.7692\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5179 - acc: 0.8022 - val_loss: 0.5241 - val_acc: 0.8022\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5031 - acc: 0.8214 - val_loss: 0.5092 - val_acc: 0.8242\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4889 - acc: 0.8324 - val_loss: 0.4950 - val_acc: 0.8352\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4753 - acc: 0.8407 - val_loss: 0.4814 - val_acc: 0.8462\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4623 - acc: 0.8489 - val_loss: 0.4684 - val_acc: 0.8462\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4498 - acc: 0.8544 - val_loss: 0.4559 - val_acc: 0.8571\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4379 - acc: 0.8599 - val_loss: 0.4439 - val_acc: 0.8681\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4264 - acc: 0.8709 - val_loss: 0.4324 - val_acc: 0.8681\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4155 - acc: 0.8846 - val_loss: 0.4214 - val_acc: 0.8681\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4050 - acc: 0.8874 - val_loss: 0.4109 - val_acc: 0.8791\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3950 - acc: 0.8929 - val_loss: 0.4008 - val_acc: 0.8791\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3854 - acc: 0.8956 - val_loss: 0.3912 - val_acc: 0.8791\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3762 - acc: 0.9038 - val_loss: 0.3820 - val_acc: 0.8791\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3675 - acc: 0.9038 - val_loss: 0.3732 - val_acc: 0.8791\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3591 - acc: 0.9038 - val_loss: 0.3647 - val_acc: 0.8791\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3510 - acc: 0.9066 - val_loss: 0.3567 - val_acc: 0.8901\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3433 - acc: 0.9093 - val_loss: 0.3489 - val_acc: 0.8901\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3360 - acc: 0.9121 - val_loss: 0.3415 - val_acc: 0.8901\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3289 - acc: 0.9121 - val_loss: 0.3345 - val_acc: 0.8901\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3222 - acc: 0.9148 - val_loss: 0.3277 - val_acc: 0.8901\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3157 - acc: 0.9148 - val_loss: 0.3213 - val_acc: 0.8901\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3095 - acc: 0.9176 - val_loss: 0.3151 - val_acc: 0.8901\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3036 - acc: 0.9176 - val_loss: 0.3092 - val_acc: 0.8901\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2979 - acc: 0.9176 - val_loss: 0.3036 - val_acc: 0.8901\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2925 - acc: 0.9176 - val_loss: 0.2982 - val_acc: 0.8901\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2873 - acc: 0.9176 - val_loss: 0.2931 - val_acc: 0.8901\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2823 - acc: 0.9176 - val_loss: 0.2881 - val_acc: 0.8901\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2775 - acc: 0.9176 - val_loss: 0.2835 - val_acc: 0.8791\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2729 - acc: 0.9203 - val_loss: 0.2790 - val_acc: 0.8791\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2685 - acc: 0.9203 - val_loss: 0.2747 - val_acc: 0.9011\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2643 - acc: 0.9231 - val_loss: 0.2706 - val_acc: 0.9011\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2602 - acc: 0.9286 - val_loss: 0.2667 - val_acc: 0.9121\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2563 - acc: 0.9286 - val_loss: 0.2629 - val_acc: 0.9121\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2526 - acc: 0.9313 - val_loss: 0.2593 - val_acc: 0.9231\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2490 - acc: 0.9341 - val_loss: 0.2559 - val_acc: 0.9231\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2455 - acc: 0.9368 - val_loss: 0.2526 - val_acc: 0.9231\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2422 - acc: 0.9368 - val_loss: 0.2495 - val_acc: 0.9231\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2390 - acc: 0.9368 - val_loss: 0.2465 - val_acc: 0.9231\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2359 - acc: 0.9368 - val_loss: 0.2436 - val_acc: 0.9231\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2330 - acc: 0.9368 - val_loss: 0.2409 - val_acc: 0.9231\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2301 - acc: 0.9368 - val_loss: 0.2383 - val_acc: 0.9231\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2273 - acc: 0.9368 - val_loss: 0.2357 - val_acc: 0.9231\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2247 - acc: 0.9368 - val_loss: 0.2333 - val_acc: 0.9231\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2221 - acc: 0.9368 - val_loss: 0.2310 - val_acc: 0.9231\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2197 - acc: 0.9396 - val_loss: 0.2288 - val_acc: 0.9231\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2173 - acc: 0.9396 - val_loss: 0.2267 - val_acc: 0.9231\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2150 - acc: 0.9396 - val_loss: 0.2246 - val_acc: 0.9231\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2127 - acc: 0.9396 - val_loss: 0.2227 - val_acc: 0.9231\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2106 - acc: 0.9396 - val_loss: 0.2208 - val_acc: 0.9231\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2085 - acc: 0.9396 - val_loss: 0.2190 - val_acc: 0.9231\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2065 - acc: 0.9396 - val_loss: 0.2172 - val_acc: 0.9231\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2045 - acc: 0.9396 - val_loss: 0.2155 - val_acc: 0.9231\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2026 - acc: 0.9396 - val_loss: 0.2139 - val_acc: 0.9231\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2008 - acc: 0.9396 - val_loss: 0.2124 - val_acc: 0.9231\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1990 - acc: 0.9396 - val_loss: 0.2109 - val_acc: 0.9231\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1973 - acc: 0.9368 - val_loss: 0.2095 - val_acc: 0.9231\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1957 - acc: 0.9368 - val_loss: 0.2081 - val_acc: 0.9231\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1940 - acc: 0.9368 - val_loss: 0.2067 - val_acc: 0.9231\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1925 - acc: 0.9368 - val_loss: 0.2055 - val_acc: 0.9231\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1909 - acc: 0.9368 - val_loss: 0.2042 - val_acc: 0.9231\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1895 - acc: 0.9368 - val_loss: 0.2030 - val_acc: 0.9231\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1880 - acc: 0.9368 - val_loss: 0.2019 - val_acc: 0.9231\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1866 - acc: 0.9368 - val_loss: 0.2008 - val_acc: 0.9231\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1853 - acc: 0.9368 - val_loss: 0.1997 - val_acc: 0.9231\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1839 - acc: 0.9368 - val_loss: 0.1987 - val_acc: 0.9231\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1826 - acc: 0.9368 - val_loss: 0.1977 - val_acc: 0.9231\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1814 - acc: 0.9368 - val_loss: 0.1967 - val_acc: 0.9231\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1802 - acc: 0.9368 - val_loss: 0.1958 - val_acc: 0.9231\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1790 - acc: 0.9368 - val_loss: 0.1949 - val_acc: 0.9231\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1778 - acc: 0.9341 - val_loss: 0.1940 - val_acc: 0.9231\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1767 - acc: 0.9341 - val_loss: 0.1931 - val_acc: 0.9231\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1756 - acc: 0.9368 - val_loss: 0.1923 - val_acc: 0.9231\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1745 - acc: 0.9341 - val_loss: 0.1915 - val_acc: 0.9231\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1734 - acc: 0.9368 - val_loss: 0.1908 - val_acc: 0.9231\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1724 - acc: 0.9368 - val_loss: 0.1900 - val_acc: 0.9231\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1714 - acc: 0.9368 - val_loss: 0.1893 - val_acc: 0.9231\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1704 - acc: 0.9368 - val_loss: 0.1886 - val_acc: 0.9231\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1695 - acc: 0.9368 - val_loss: 0.1879 - val_acc: 0.9231\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1685 - acc: 0.9368 - val_loss: 0.1873 - val_acc: 0.9231\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1676 - acc: 0.9396 - val_loss: 0.1867 - val_acc: 0.9231\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1667 - acc: 0.9396 - val_loss: 0.1861 - val_acc: 0.9231\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1658 - acc: 0.9396 - val_loss: 0.1855 - val_acc: 0.9231\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1650 - acc: 0.9396 - val_loss: 0.1849 - val_acc: 0.9231\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1641 - acc: 0.9396 - val_loss: 0.1843 - val_acc: 0.9231\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1633 - acc: 0.9396 - val_loss: 0.1838 - val_acc: 0.9231\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1625 - acc: 0.9396 - val_loss: 0.1833 - val_acc: 0.9231\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1617 - acc: 0.9396 - val_loss: 0.1827 - val_acc: 0.9231\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1609 - acc: 0.9396 - val_loss: 0.1822 - val_acc: 0.9231\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1602 - acc: 0.9396 - val_loss: 0.1818 - val_acc: 0.9231\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1594 - acc: 0.9396 - val_loss: 0.1813 - val_acc: 0.9231\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1587 - acc: 0.9396 - val_loss: 0.1808 - val_acc: 0.9231\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1580 - acc: 0.9396 - val_loss: 0.1804 - val_acc: 0.9231\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1573 - acc: 0.9368 - val_loss: 0.1800 - val_acc: 0.9231\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1566 - acc: 0.9368 - val_loss: 0.1795 - val_acc: 0.9231\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1559 - acc: 0.9368 - val_loss: 0.1791 - val_acc: 0.9231\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1553 - acc: 0.9368 - val_loss: 0.1787 - val_acc: 0.9231\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1546 - acc: 0.9368 - val_loss: 0.1784 - val_acc: 0.9231\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1540 - acc: 0.9368 - val_loss: 0.1780 - val_acc: 0.9231\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1534 - acc: 0.9368 - val_loss: 0.1776 - val_acc: 0.9231\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1528 - acc: 0.9368 - val_loss: 0.1773 - val_acc: 0.9231\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1522 - acc: 0.9368 - val_loss: 0.1769 - val_acc: 0.9231\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1516 - acc: 0.9368 - val_loss: 0.1766 - val_acc: 0.9231\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1510 - acc: 0.9368 - val_loss: 0.1763 - val_acc: 0.9231\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1504 - acc: 0.9368 - val_loss: 0.1759 - val_acc: 0.9231\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1499 - acc: 0.9368 - val_loss: 0.1756 - val_acc: 0.9231\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1493 - acc: 0.9368 - val_loss: 0.1753 - val_acc: 0.9231\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1488 - acc: 0.9368 - val_loss: 0.1750 - val_acc: 0.9231\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1482 - acc: 0.9368 - val_loss: 0.1747 - val_acc: 0.9231\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1477 - acc: 0.9368 - val_loss: 0.1745 - val_acc: 0.9231\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1472 - acc: 0.9368 - val_loss: 0.1742 - val_acc: 0.9231\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1467 - acc: 0.9368 - val_loss: 0.1739 - val_acc: 0.9231\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1462 - acc: 0.9368 - val_loss: 0.1737 - val_acc: 0.9231\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1457 - acc: 0.9368 - val_loss: 0.1734 - val_acc: 0.9231\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1452 - acc: 0.9368 - val_loss: 0.1732 - val_acc: 0.9231\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1448 - acc: 0.9396 - val_loss: 0.1729 - val_acc: 0.9231\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1443 - acc: 0.9396 - val_loss: 0.1727 - val_acc: 0.9231\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1438 - acc: 0.9396 - val_loss: 0.1725 - val_acc: 0.9231\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1434 - acc: 0.9396 - val_loss: 0.1722 - val_acc: 0.9231\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1429 - acc: 0.9396 - val_loss: 0.1720 - val_acc: 0.9231\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1425 - acc: 0.9396 - val_loss: 0.1718 - val_acc: 0.9231\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1421 - acc: 0.9396 - val_loss: 0.1716 - val_acc: 0.9231\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1417 - acc: 0.9396 - val_loss: 0.1714 - val_acc: 0.9231\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1412 - acc: 0.9396 - val_loss: 0.1712 - val_acc: 0.9231\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1408 - acc: 0.9396 - val_loss: 0.1710 - val_acc: 0.9231\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1404 - acc: 0.9396 - val_loss: 0.1708 - val_acc: 0.9231\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1400 - acc: 0.9396 - val_loss: 0.1707 - val_acc: 0.9231\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1396 - acc: 0.9396 - val_loss: 0.1705 - val_acc: 0.9231\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1392 - acc: 0.9396 - val_loss: 0.1703 - val_acc: 0.9231\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1389 - acc: 0.9396 - val_loss: 0.1701 - val_acc: 0.9231\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1385 - acc: 0.9396 - val_loss: 0.1700 - val_acc: 0.9231\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1381 - acc: 0.9396 - val_loss: 0.1698 - val_acc: 0.9121\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1378 - acc: 0.9396 - val_loss: 0.1697 - val_acc: 0.9121\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1374 - acc: 0.9396 - val_loss: 0.1695 - val_acc: 0.9121\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1370 - acc: 0.9396 - val_loss: 0.1694 - val_acc: 0.9121\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1367 - acc: 0.9396 - val_loss: 0.1692 - val_acc: 0.9121\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1364 - acc: 0.9396 - val_loss: 0.1691 - val_acc: 0.9121\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1360 - acc: 0.9396 - val_loss: 0.1689 - val_acc: 0.9121\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1357 - acc: 0.9396 - val_loss: 0.1688 - val_acc: 0.9121\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1354 - acc: 0.9396 - val_loss: 0.1687 - val_acc: 0.9121\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1350 - acc: 0.9396 - val_loss: 0.1686 - val_acc: 0.9121\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1347 - acc: 0.9396 - val_loss: 0.1684 - val_acc: 0.9121\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1344 - acc: 0.9396 - val_loss: 0.1683 - val_acc: 0.9121\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1341 - acc: 0.9396 - val_loss: 0.1682 - val_acc: 0.9121\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1338 - acc: 0.9396 - val_loss: 0.1681 - val_acc: 0.9121\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1335 - acc: 0.9396 - val_loss: 0.1680 - val_acc: 0.9121\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1332 - acc: 0.9396 - val_loss: 0.1679 - val_acc: 0.9121\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1329 - acc: 0.9396 - val_loss: 0.1678 - val_acc: 0.9121\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1326 - acc: 0.9396 - val_loss: 0.1677 - val_acc: 0.9121\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1323 - acc: 0.9396 - val_loss: 0.1676 - val_acc: 0.9121\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1320 - acc: 0.9396 - val_loss: 0.1675 - val_acc: 0.9121\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1317 - acc: 0.9396 - val_loss: 0.1674 - val_acc: 0.9121\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1315 - acc: 0.9396 - val_loss: 0.1673 - val_acc: 0.9121\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1312 - acc: 0.9396 - val_loss: 0.1672 - val_acc: 0.9121\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1309 - acc: 0.9396 - val_loss: 0.1671 - val_acc: 0.9121\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1307 - acc: 0.9396 - val_loss: 0.1670 - val_acc: 0.9121\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1304 - acc: 0.9396 - val_loss: 0.1669 - val_acc: 0.9121\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1301 - acc: 0.9396 - val_loss: 0.1669 - val_acc: 0.9121\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1299 - acc: 0.9396 - val_loss: 0.1668 - val_acc: 0.9121\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1296 - acc: 0.9396 - val_loss: 0.1667 - val_acc: 0.9121\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1294 - acc: 0.9396 - val_loss: 0.1666 - val_acc: 0.9121\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1291 - acc: 0.9396 - val_loss: 0.1666 - val_acc: 0.9121\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1289 - acc: 0.9396 - val_loss: 0.1665 - val_acc: 0.9121\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1286 - acc: 0.9396 - val_loss: 0.1664 - val_acc: 0.9121\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1284 - acc: 0.9423 - val_loss: 0.1664 - val_acc: 0.9121\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1282 - acc: 0.9423 - val_loss: 0.1663 - val_acc: 0.9121\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1279 - acc: 0.9423 - val_loss: 0.1662 - val_acc: 0.9121\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1277 - acc: 0.9423 - val_loss: 0.1662 - val_acc: 0.9121\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1275 - acc: 0.9423 - val_loss: 0.1661 - val_acc: 0.9121\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1273 - acc: 0.9423 - val_loss: 0.1661 - val_acc: 0.9121\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1270 - acc: 0.9423 - val_loss: 0.1660 - val_acc: 0.9121\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1268 - acc: 0.9423 - val_loss: 0.1659 - val_acc: 0.9121\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1266 - acc: 0.9423 - val_loss: 0.1659 - val_acc: 0.9121\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1264 - acc: 0.9423 - val_loss: 0.1658 - val_acc: 0.9121\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1262 - acc: 0.9423 - val_loss: 0.1658 - val_acc: 0.9121\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1260 - acc: 0.9423 - val_loss: 0.1657 - val_acc: 0.9121\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1258 - acc: 0.9423 - val_loss: 0.1657 - val_acc: 0.9121\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1256 - acc: 0.9423 - val_loss: 0.1657 - val_acc: 0.9121\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1254 - acc: 0.9451 - val_loss: 0.1656 - val_acc: 0.9121\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1252 - acc: 0.9451 - val_loss: 0.1656 - val_acc: 0.9121\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1250 - acc: 0.9451 - val_loss: 0.1655 - val_acc: 0.9121\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1248 - acc: 0.9451 - val_loss: 0.1655 - val_acc: 0.9121\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1246 - acc: 0.9478 - val_loss: 0.1655 - val_acc: 0.9121\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1244 - acc: 0.9478 - val_loss: 0.1654 - val_acc: 0.9121\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1242 - acc: 0.9478 - val_loss: 0.1654 - val_acc: 0.9121\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1240 - acc: 0.9505 - val_loss: 0.1654 - val_acc: 0.9121\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1238 - acc: 0.9505 - val_loss: 0.1653 - val_acc: 0.9121\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1236 - acc: 0.9505 - val_loss: 0.1653 - val_acc: 0.9121\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1235 - acc: 0.9505 - val_loss: 0.1653 - val_acc: 0.9121\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1233 - acc: 0.9505 - val_loss: 0.1652 - val_acc: 0.9121\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1231 - acc: 0.9505 - val_loss: 0.1652 - val_acc: 0.9121\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1229 - acc: 0.9505 - val_loss: 0.1652 - val_acc: 0.9121\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1228 - acc: 0.9505 - val_loss: 0.1652 - val_acc: 0.9121\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1226 - acc: 0.9505 - val_loss: 0.1651 - val_acc: 0.9121\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1224 - acc: 0.9505 - val_loss: 0.1651 - val_acc: 0.9121\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1222 - acc: 0.9505 - val_loss: 0.1651 - val_acc: 0.9121\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1221 - acc: 0.9505 - val_loss: 0.1651 - val_acc: 0.9121\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1219 - acc: 0.9505 - val_loss: 0.1650 - val_acc: 0.9121\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1218 - acc: 0.9505 - val_loss: 0.1650 - val_acc: 0.9121\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1216 - acc: 0.9505 - val_loss: 0.1650 - val_acc: 0.9121\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1214 - acc: 0.9505 - val_loss: 0.1650 - val_acc: 0.9121\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1213 - acc: 0.9505 - val_loss: 0.1650 - val_acc: 0.9121\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1211 - acc: 0.9505 - val_loss: 0.1650 - val_acc: 0.9121\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1210 - acc: 0.9505 - val_loss: 0.1649 - val_acc: 0.9121\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1208 - acc: 0.9505 - val_loss: 0.1649 - val_acc: 0.9121\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1207 - acc: 0.9505 - val_loss: 0.1649 - val_acc: 0.9121\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1205 - acc: 0.9505 - val_loss: 0.1649 - val_acc: 0.9121\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1204 - acc: 0.9505 - val_loss: 0.1649 - val_acc: 0.9121\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1202 - acc: 0.9505 - val_loss: 0.1649 - val_acc: 0.9121\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1201 - acc: 0.9505 - val_loss: 0.1649 - val_acc: 0.9121\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1199 - acc: 0.9505 - val_loss: 0.1648 - val_acc: 0.9121\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1198 - acc: 0.9505 - val_loss: 0.1648 - val_acc: 0.9121\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1196 - acc: 0.9505 - val_loss: 0.1648 - val_acc: 0.9121\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1195 - acc: 0.9505 - val_loss: 0.1648 - val_acc: 0.9121\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1194 - acc: 0.9505 - val_loss: 0.1648 - val_acc: 0.9121\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1192 - acc: 0.9505 - val_loss: 0.1648 - val_acc: 0.9121\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1191 - acc: 0.9505 - val_loss: 0.1648 - val_acc: 0.9121\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1189 - acc: 0.9478 - val_loss: 0.1648 - val_acc: 0.9121\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1188 - acc: 0.9478 - val_loss: 0.1648 - val_acc: 0.9121\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1187 - acc: 0.9478 - val_loss: 0.1648 - val_acc: 0.9121\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1185 - acc: 0.9478 - val_loss: 0.1648 - val_acc: 0.9121\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1184 - acc: 0.9478 - val_loss: 0.1648 - val_acc: 0.9121\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1183 - acc: 0.9478 - val_loss: 0.1648 - val_acc: 0.9121\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1181 - acc: 0.9478 - val_loss: 0.1648 - val_acc: 0.9121\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1180 - acc: 0.9478 - val_loss: 0.1647 - val_acc: 0.9121\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1179 - acc: 0.9478 - val_loss: 0.1647 - val_acc: 0.9121\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1178 - acc: 0.9478 - val_loss: 0.1647 - val_acc: 0.9121\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1176 - acc: 0.9478 - val_loss: 0.1647 - val_acc: 0.9121\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1175 - acc: 0.9478 - val_loss: 0.1647 - val_acc: 0.9121\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1174 - acc: 0.9478 - val_loss: 0.1647 - val_acc: 0.9121\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1173 - acc: 0.9478 - val_loss: 0.1647 - val_acc: 0.9121\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1172 - acc: 0.9478 - val_loss: 0.1647 - val_acc: 0.9121\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1170 - acc: 0.9478 - val_loss: 0.1647 - val_acc: 0.9121\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1169 - acc: 0.9478 - val_loss: 0.1647 - val_acc: 0.9121\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1168 - acc: 0.9478 - val_loss: 0.1647 - val_acc: 0.9121\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1167 - acc: 0.9478 - val_loss: 0.1647 - val_acc: 0.9121\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1166 - acc: 0.9478 - val_loss: 0.1647 - val_acc: 0.9121\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1164 - acc: 0.9478 - val_loss: 0.1647 - val_acc: 0.9121\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1163 - acc: 0.9478 - val_loss: 0.1647 - val_acc: 0.9121\n",
      "Epoch 247: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "         callbacks=[es, mc], batch_size=2048, epochs=1000,\n",
    "         validation_split=.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9554d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76ff9a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred.argmax(axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb8cb881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.title('Accuracy : Training vs Validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b1ff8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss : Training vs Validation')\n",
    "plt.legend(['Training', 'Validation'], loc= 0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
